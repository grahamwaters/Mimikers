{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "stopwords = set(english_stopwords)\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "# read card_deck from ppn_deck.json file\n",
    "with open(\"ppn_deck.json\", \"r\") as read_file:\n",
    "    card_deck = json.load(read_file)\n",
    "\n",
    "def revise_point_values(card_deck, max_points=10):\n",
    "    # Initialize a dictionary to store the word counts for each card\n",
    "    word_counts = {}\n",
    "    # Initialize a list to store the word counts for each card\n",
    "    card_word_counts = []\n",
    "    \n",
    "    # Get a list of English stopwords\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    # Iterate through each card in the card deck\n",
    "    card_id = 0\n",
    "    for card in tqdm(card_deck):\n",
    "        # Get the card's id from the iteration\n",
    "        # Get the summary for the card\n",
    "        summary = card['summary']\n",
    "        # Split the summary into words. Currently it is a tuple, get the second element.\n",
    "        summary_text = summary[1]\n",
    "        # Split the summary into words\n",
    "        words = summary_text.split()\n",
    "        # Remove the stop words from the list of words\n",
    "        nonstop_words = [word for word in words if word not in stop_words]\n",
    "        # Calculate the number of non-stop words\n",
    "        word_count = len(nonstop_words)\n",
    "        # Add the word count to the dictionary\n",
    "        word_counts[card_id] = word_count\n",
    "        # Append the word count to the list of card word counts\n",
    "        card_word_counts.append(word_count)\n",
    "        # Increment the card id\n",
    "        card_id += 1\n",
    "    # Scale the word counts to be between 0 and 10\n",
    "    scaled_word_counts = scaler.fit_transform(pd.DataFrame(card_word_counts))\n",
    "    # Iterate through each card in the card deck\n",
    "    card_id = 0\n",
    "    for card in tqdm(card_deck):\n",
    "        #print(card)\n",
    "        # Get the card's id from the iteration\n",
    "        # Get the scaled word count for the card\n",
    "        scaled_word_count = scaled_word_counts[card_id]\n",
    "        # Get the card's point value if it exists\n",
    "        # point_value = card['point_value'] if 'point_value' in card else 0\n",
    "        rounded_value = int(scaled_word_count[0])\n",
    "\n",
    "        # Update the card's point value to the scaled word count\n",
    "        card['point_value'] = rounded_value\n",
    "        # Increment the card id\n",
    "        card_id += 1\n",
    "    return card_deck\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this, you can reshape card_word_counts to a 2D array using the reshape method of the numpy library, like this: card_word_counts.reshape(-1, 1). This will transform card_word_counts into a 2D array with a single column and as many rows as there are elements in card_word_counts.\n",
    "\n",
    "You can then pass the reshaped array to the fit method of the MinMaxScaler object.\n",
    "\n",
    "You will also need to make the same change to the line card_word_counts_scaled = scaler.fit_transform(card_word_counts.reshape(-1, 1)) in order to avoid the same error when you try to fit the scaler to the data.\n",
    "\n",
    "Finally, in the for loop where you update the point value for each card, you should use card_word_counts_scaled[card_id] instead of card_word_counts_scaled[word_count]. This is because card_word_counts_scaled is a list of scaled word counts, and you need to use the current card_id to index into the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5754/5754 [00:01<00:00, 4124.45it/s]\n",
      "100%|██████████| 5754/5754 [00:00<00:00, 1723243.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# revise point values\n",
    "card_deck = revise_point_values(card_deck,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>related</th>\n",
       "      <th>summary_short</th>\n",
       "      <th>summary_clean</th>\n",
       "      <th>point_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Climate change and cities</td>\n",
       "      <td>[Climate change and cities, Climate change and...</td>\n",
       "      <td>401</td>\n",
       "      <td>Moreover, because most cities have been built ...</td>\n",
       "      <td>Moreover because of processes that create clim...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rosetta Cammeniti</td>\n",
       "      <td>[Rosetta Cammeniti, Rosetta Cammeniti, Rosetta...</td>\n",
       "      <td>321</td>\n",
       "      <td>['Rosetta Cammeniti', 'Rosetta Cammeniti, Rose...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spy Muppets: License to Croak</td>\n",
       "      <td>[Spy Muppets: License to Croak, Spy Muppets: L...</td>\n",
       "      <td>164</td>\n",
       "      <td>['Spy Muppets: License to Croak', 'Spy Muppets...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fame in the 20th Century</td>\n",
       "      <td>[Fame in the 20th Century, Fame in the 20th Ce...</td>\n",
       "      <td>591</td>\n",
       "      <td>['Fame in the 20th Century', 'Fame in the 20th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Becca Hayton</td>\n",
       "      <td>[Becca Hayton, Becca Hayton, Becca Dean also H...</td>\n",
       "      <td>271</td>\n",
       "      <td>['Becca Hayton', 'Becca Hayton, Becca Dean als...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0      Climate change and cities   \n",
       "1              Rosetta Cammeniti   \n",
       "2  Spy Muppets: License to Croak   \n",
       "3       Fame in the 20th Century   \n",
       "4                   Becca Hayton   \n",
       "\n",
       "                                             summary related  \\\n",
       "0  [Climate change and cities, Climate change and...     401   \n",
       "1  [Rosetta Cammeniti, Rosetta Cammeniti, Rosetta...     321   \n",
       "2  [Spy Muppets: License to Croak, Spy Muppets: L...     164   \n",
       "3  [Fame in the 20th Century, Fame in the 20th Ce...     591   \n",
       "4  [Becca Hayton, Becca Hayton, Becca Dean also H...     271   \n",
       "\n",
       "                                       summary_short  \\\n",
       "0  Moreover, because most cities have been built ...   \n",
       "1  ['Rosetta Cammeniti', 'Rosetta Cammeniti, Rose...   \n",
       "2  ['Spy Muppets: License to Croak', 'Spy Muppets...   \n",
       "3  ['Fame in the 20th Century', 'Fame in the 20th...   \n",
       "4  ['Becca Hayton', 'Becca Hayton, Becca Dean als...   \n",
       "\n",
       "                                       summary_clean  point_value  \n",
       "0  Moreover because of processes that create clim...            4  \n",
       "1                                                NaN            0  \n",
       "2                                                NaN            0  \n",
       "3                                                NaN            1  \n",
       "4                                                NaN            0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show an example with the revised point values\n",
    "# convert to dataframe\n",
    "df = pd.DataFrame(card_deck)\n",
    "# show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the summary_short needs to always be the second element in the tuple if it is an instance of a tuple, else it is itself (str)\n",
    "for card in card_deck:\n",
    "    summary = card['summary']\n",
    "    if isinstance(summary, tuple) or isinstance(summary, list):\n",
    "        summary_short = summary[1]\n",
    "    else:\n",
    "        summary_short = summary\n",
    "    card['summary_short'] = summary_short\n",
    "    card['summary'] = summary_short\n",
    "\n",
    "df = pd.DataFrame(card_deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the point_value must always be a value from 1 to 10 never 0. Replace all 0's with 1's\n",
    "df['point_value'] = df['point_value'].replace(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>related</th>\n",
       "      <th>summary_short</th>\n",
       "      <th>summary_clean</th>\n",
       "      <th>point_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Climate change and cities</td>\n",
       "      <td>Climate change and cities are deeply connected...</td>\n",
       "      <td>401</td>\n",
       "      <td>Climate change and cities are deeply connected...</td>\n",
       "      <td>Moreover because of processes that create clim...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rosetta Cammeniti</td>\n",
       "      <td>Rosetta Cammeniti, Rosetta Rosie Cammeniti is ...</td>\n",
       "      <td>321</td>\n",
       "      <td>Rosetta Cammeniti, Rosetta Rosie Cammeniti is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spy Muppets: License to Croak</td>\n",
       "      <td>Spy Muppets: License to Croak, Spy Muppets: Li...</td>\n",
       "      <td>164</td>\n",
       "      <td>Spy Muppets: License to Croak, Spy Muppets: Li...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fame in the 20th Century</td>\n",
       "      <td>Fame in the 20th Century, Fame in the 20th Cen...</td>\n",
       "      <td>591</td>\n",
       "      <td>Fame in the 20th Century, Fame in the 20th Cen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Becca Hayton</td>\n",
       "      <td>Becca Hayton, Becca Dean also Hayton is a fict...</td>\n",
       "      <td>271</td>\n",
       "      <td>Becca Hayton, Becca Dean also Hayton is a fict...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0      Climate change and cities   \n",
       "1              Rosetta Cammeniti   \n",
       "2  Spy Muppets: License to Croak   \n",
       "3       Fame in the 20th Century   \n",
       "4                   Becca Hayton   \n",
       "\n",
       "                                             summary related  \\\n",
       "0  Climate change and cities are deeply connected...     401   \n",
       "1  Rosetta Cammeniti, Rosetta Rosie Cammeniti is ...     321   \n",
       "2  Spy Muppets: License to Croak, Spy Muppets: Li...     164   \n",
       "3  Fame in the 20th Century, Fame in the 20th Cen...     591   \n",
       "4  Becca Hayton, Becca Dean also Hayton is a fict...     271   \n",
       "\n",
       "                                       summary_short  \\\n",
       "0  Climate change and cities are deeply connected...   \n",
       "1  Rosetta Cammeniti, Rosetta Rosie Cammeniti is ...   \n",
       "2  Spy Muppets: License to Croak, Spy Muppets: Li...   \n",
       "3  Fame in the 20th Century, Fame in the 20th Cen...   \n",
       "4  Becca Hayton, Becca Dean also Hayton is a fict...   \n",
       "\n",
       "                                       summary_clean  point_value  \n",
       "0  Moreover because of processes that create clim...            4  \n",
       "1                                                NaN            1  \n",
       "2                                                NaN            1  \n",
       "3                                                NaN            1  \n",
       "4                                                NaN            1  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now save the df as a json file\n",
    "card_deck = df.to_dict('records')\n",
    "with open(\"ppn_deck.json\", \"w\") as write_file:\n",
    "    json.dump(card_deck, write_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
