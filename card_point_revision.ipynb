{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "stopwords = set(english_stopwords)\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# read card_deck from ppn_deck.json file\n",
    "with open(\"ppn_deck.json\", \"r\") as read_file:\n",
    "    card_deck = json.load(read_file)\n",
    "\n",
    "def revise_point_values(card_deck, max_points=10):\n",
    "    # Initialize a dictionary to store the word counts for each card\n",
    "    word_counts = {}\n",
    "    # Initialize a list to store the word counts for each card\n",
    "    card_word_counts = []\n",
    "    \n",
    "    # Get a list of English stopwords\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    # Iterate through each card in the card deck\n",
    "    card_id = 0\n",
    "    for card in tqdm(card_deck):\n",
    "        # Get the card's id from the iteration\n",
    "        # Get the summary for the card\n",
    "        summary = card['summary']\n",
    "        # Split the summary into words. Currently it is a tuple, get the second element.\n",
    "        summary_text = summary[1]\n",
    "        # Split the summary into words\n",
    "        words = summary_text.split()\n",
    "        # Remove the stop words from the list of words\n",
    "        nonstop_words = [word for word in words if word not in stop_words]\n",
    "        # Calculate the number of non-stop words\n",
    "        word_count = len(nonstop_words)\n",
    "        # Add the word count to the dictionary\n",
    "        word_counts[card_id] = word_count\n",
    "        # Append the word count to the list of card word counts\n",
    "        card_word_counts.append(word_count)\n",
    "        # Increment the card id\n",
    "        card_id += 1\n",
    "    # Use MinMaxScaler to scale the word counts to a range of 1 to 100\n",
    "    scaler = MinMaxScaler(feature_range=(1, int(max_points)))\n",
    "    scaled_word_counts = scaler.fit_transform(pd.DataFrame(card_word_counts))\n",
    "    # Iterate through each card in the card deck\n",
    "    card_id = 0\n",
    "    for card in tqdm(card_deck):\n",
    "        #print(card)\n",
    "        # Get the card's id from the iteration\n",
    "        # Get the scaled word count for the card\n",
    "        scaled_word_count = scaled_word_counts[card_id]\n",
    "        # Get the card's point value if it exists\n",
    "        # point_value = card['point_value'] if 'point_value' in card else 0\n",
    "        rounded_value = int(scaled_word_count[0])\n",
    "\n",
    "        # Update the card's point value to the scaled word count\n",
    "        card['point_value'] = rounded_value\n",
    "        # Increment the card id\n",
    "        card_id += 1\n",
    "    return card_deck\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this, you can reshape card_word_counts to a 2D array using the reshape method of the numpy library, like this: card_word_counts.reshape(-1, 1). This will transform card_word_counts into a 2D array with a single column and as many rows as there are elements in card_word_counts.\n",
    "\n",
    "You can then pass the reshaped array to the fit method of the MinMaxScaler object.\n",
    "\n",
    "You will also need to make the same change to the line card_word_counts_scaled = scaler.fit_transform(card_word_counts.reshape(-1, 1)) in order to avoid the same error when you try to fit the scaler to the data.\n",
    "\n",
    "Finally, in the for loop where you update the point value for each card, you should use card_word_counts_scaled[card_id] instead of card_word_counts_scaled[word_count]. This is because card_word_counts_scaled is a list of scaled word counts, and you need to use the current card_id to index into the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4053/4053 [00:00<00:00, 4891.03it/s]\n",
      "100%|██████████| 4053/4053 [00:00<00:00, 1760695.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# revise point values\n",
    "card_deck = revise_point_values(card_deck,10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
