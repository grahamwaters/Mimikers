{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make function for wiki pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import requests\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "from tqdm import tqdm\n",
    "URL = \"https://randomincategory.toolforge.org/Random_page_in_category?\"\n",
    "URL += f\"category={urllib.parse.quote('famous fictional characters')}\"\n",
    "URL += f\"&category2={urllib.parse.quote('historical figures')}\"\n",
    "URL += f\"&category3={urllib.parse.quote('slogans')}\"\n",
    "URL += f\"&category4={urllib.parse.quote('catchphrases')}\"\n",
    "URL += f\"&category5={urllib.parse.quote('authors')}\"\n",
    "URL += f\"&category6={urllib.parse.quote('actors')}\"\n",
    "URL += f\"&category7={urllib.parse.quote('british authors')}\"\n",
    "URL += f\"&category8={urllib.parse.quote('american authors')}\"\n",
    "URL += f\"&category9={urllib.parse.quote('musicians')}\"\n",
    "URL += f\"&category10={urllib.parse.quote('songs')}\"\n",
    "URL += f\"&category11={urllib.parse.quote('books')}\"\n",
    "URL += f\"&category12={urllib.parse.quote('movies')}\"\n",
    "URL += \"&server=en.wikipedia.org&cmnamespace=&cmtype=page&returntype=\"\n",
    "\n",
    "\n",
    "replacements = {\n",
    "    r'\\bsex\\b': 'affection',\n",
    "    r'\\bporn\\w*\\b': 'adult entertainment',\n",
    "    r'fuck': 'have intimate relations with',\n",
    "    r'fucking': 'romancing, physically',\n",
    "    r'\\bfuck\\w*\\b': ' (bleep) ',\n",
    "    r'\\bass\\b': 'dump truck',\n",
    "    r'\\bshit\\w*\\b': 'poop',\n",
    "    r'damn\\w*\\b': 'darn',\n",
    "    r'god-damn\\w*\\b|goddamn\\w*\\b': 'super darn',\n",
    "    r'\\bass\\b|\\wasse*': 'rear end',\n",
    "    r'cock': 'rooster',\n",
    "    r'small dick energy':'little man syndrome',\n",
    "    r'\\bdick\\w*\\b': ' johnson ',\n",
    "    r'ppl':'people',\n",
    "    '\\bwat\\b':'what',\n",
    "    r'a black': 'an african-american',\n",
    "    r'black person':'dark skinned person',\n",
    "    r'\\bpee\\b' : 'urinate',\n",
    "    r'\\bpiss\\b': 'urinate',\n",
    "    r'\\b(peeing|pissing)': 'urinating',\n",
    "    r'white person':'caucasian',\n",
    "    r'\\bwhore\\w*\\b': 'prostitute',\n",
    "    r'nigg*': 'racial slur',\n",
    "    '\\r\\n':' ',\n",
    "    r'\\bslut\\b': ' loose person ',\n",
    "    r'\\bblowjob\\b': 'random gift',\n",
    "    r'racist': 'ignorant',\n",
    "    'racism':'fear of people that look different',\n",
    "    r'faggot': 'gay person',\n",
    "    r'\\bfag\\w*\\b':'gay person',\n",
    "    r'boob|boob*|breast': 'lady pillows',\n",
    "    r'\\bbitch*\\b': 'mean woman',\n",
    "    r'bastard*': 'illegitimate child',\n",
    "    r'hoes?': 'chicks',\n",
    "    r'breast*|jugs': 'chest',\n",
    "    r'\\bcunt*\\b': 'comtemptible person',\n",
    "    r'\\bpuss\\w*\\b': 'vagina',\n",
    "    r'\\wdick*': 'penis',\n",
    "    r'naked': 'disrobed',\n",
    "    r'\\bnud\\w*\\b': 'unclothed',\n",
    "    r'\\nmasterbate\\w*\\b': 'self-gratified',\n",
    "    r'\\bmasturbating\\w*\\b': 'gratifying themselves',\n",
    "    r'\\b\\w{4}ilf\\b': 'person id like to get to know',\n",
    "    r'mastu\\w*\\b': 'self-gratification',\n",
    "    'god':'deity',\n",
    "    'jesus':'religious figure',\n",
    "    'christ':'religious figure',\n",
    "    'bible':'religious text',\n",
    "    'church':'place of worship',\n",
    "    'religion':'set of beliefs',\n",
    "    r'\\bpray\\w*\\b':'communicate with a deity',\n",
    "    'prayer':'a conversation with a deity',\n",
    "    'faith':'belief',\n",
    "    ' lord ':'captain',\n",
    "    ' allah ':'a diety',\n",
    "    'gay':'homosexual',\n",
    "    r' rapist ': ' intense toucher ',\n",
    "    r' rape ': ' unwelcomed tickling ', # eek I know... \n",
    "    r'pedo\\w*\\b': 'seventies mustached van driver',\n",
    "    'yahwey':'a deity',\n",
    "    'yeshua':'a religious figure',\n",
    "    ' sexual':' reproductive',\n",
    "    'douche':'chad',\n",
    "    ' sex ':' private adult time ',\n",
    "    'milf':\"mother I would like to take on a date\",\n",
    "    ' butt ':\"dumptruck/tailgate\"\n",
    "}\n",
    "\n",
    "def replacer_censor(definition,phrase,replacements_dict):\n",
    "    # Iterate over the keys in the replacements dictionary\n",
    "    for pattern in replacements_dict:\n",
    "        # Use re.sub to replace the occurrences of the pattern with its corresponding value in the phrase and definition strings\n",
    "        phrase = re.sub(pattern, replacements_dict[pattern], phrase)\n",
    "        definition = re.sub(pattern, replacements_dict[pattern], definition)\n",
    "    return phrase, definition\n",
    "\n",
    "\n",
    "def unpack_definitions(phrase,definition):\n",
    "    # remove the brackets and clean up the definitions\n",
    "    # with regex\n",
    "    definition = definition.replace(\"[\",\"\")\n",
    "    definition = definition.replace(\"]\",\"\")\n",
    "    definition = definition.replace(\"'\",\"\")\n",
    "    definition = definition.replace('\"',\"\")\n",
    "    definition = definition.replace(\"(\",\"\")\n",
    "    definition = definition.replace(\")\",\"\")\n",
    "\n",
    "    # remove double spaces\n",
    "    definition = definition.replace('  ',' ')\n",
    "    # also remove any .. by replacing them with a single .\n",
    "    definition = definition.replace('..','.')\n",
    "    # remove all non-ascii characters\n",
    "    definition = re.sub(r'[^\\x00-\\x7f]',r'', definition)\n",
    "    # remove any words that are not in the english dictionary\n",
    "    #english_words = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    #definition = re.sub(r'\\b\\w+\\b', lambda m: m.group(0) if m.group(0) in english_words else '', definition)\n",
    "    # remove extra spaces\n",
    "    #definition = re.sub(' +', ' ', definition)\n",
    "    \n",
    "    phrase, definition = replacer_censor(definition,phrase,replacements)\n",
    "    \n",
    "\n",
    "    return phrase, definition\n",
    "# limit to 1 request per second\n",
    "@sleep_and_retry\n",
    "def get_random_wiki_entry():\n",
    "\n",
    "    #print(\"getting random wiki entry from url: \",URL)\n",
    "    # use requests to get the page, then pass the redirected page url to wikipedia library.\n",
    "    req_url = requests.get(URL).url # this is a random page from the category\n",
    "    # using wikipedia library\n",
    "    page = wikipedia.page(req_url) # this is a random page from the category\n",
    "    title = page.title\n",
    "    summary = page.summary\n",
    "    #categories = page.categories\n",
    "    related = page.links\n",
    "    # create a dictionary of the entry\n",
    "    random_wiki_entry_dict = {\n",
    "        \"title\": title,\n",
    "        \"summary\": unpack_definitions(title,summary),\n",
    "        \"related\": related,\n",
    "    }\n",
    "\n",
    "    return random_wiki_entry_dict\n",
    "\n",
    "# make a card from the random wiki entry\n",
    "def create_ppn_card():\n",
    "    # create a person/place/thing card\n",
    "    # get a random wikipedia entry\n",
    "    random_wiki_entry_dict = get_random_wiki_entry()\n",
    "    # get the summary of the entry\n",
    "    random_wiki_entry_summary = random_wiki_entry_dict[\"summary\"]\n",
    "    # get the title of the entry\n",
    "    random_wiki_entry_title = random_wiki_entry_dict[\"title\"]\n",
    "    # get the categories of the entry\n",
    "    random_wiki_entry_related = random_wiki_entry_dict[\"related\"]\n",
    "\n",
    "    # create a dictionary of the entry\n",
    "    random_wiki_entry_dict = {\n",
    "        \"title\": random_wiki_entry_title,\n",
    "        \"summary\": random_wiki_entry_summary,\n",
    "        \"related\": len(random_wiki_entry_related)\n",
    "    }\n",
    "\n",
    "    return random_wiki_entry_dict\n",
    "\n",
    "# create a deck of fifty cards from the random wiki entries (non-repeating) and return the deck as a list of dictionaries\n",
    "\n",
    "def make_one_card():\n",
    "    while True:\n",
    "        try:\n",
    "            card = create_ppn_card() # create a card\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        else:\n",
    "            if len(card[\"summary\"][1]) > 10 and 'Wiki' not in card[\"title\"]: # if the card is valid\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return card\n",
    "\n",
    "def create_ppn_deck(card_count=50):\n",
    "    # create a deck of card_count cards\n",
    "    ppn_deck = []\n",
    "    for i in tqdm(range(card_count)):\n",
    "        ppn_deck.append(make_one_card())\n",
    "    return ppn_deck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 4/50 [00:19<03:40,  4.80s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_82301/2386099436.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcard_deck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ppn_deck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create a deck of 50 cards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# show the deck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_82301/1571373561.py\u001b[0m in \u001b[0;36mcreate_ppn_deck\u001b[0;34m(card_count)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mppn_deck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcard_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mppn_deck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_one_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mppn_deck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_82301/1571373561.py\u001b[0m in \u001b[0;36mmake_one_card\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mcard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ppn_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create a card\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_82301/1571373561.py\u001b[0m in \u001b[0;36mcreate_ppn_card\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m# create a person/place/thing card\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;31m# get a random wikipedia entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mrandom_wiki_entry_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_wiki_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;31m# get the summary of the entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mrandom_wiki_entry_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_wiki_entry_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"summary\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/ratelimit/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRateLimitException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_remaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_82301/1571373561.py\u001b[0m in \u001b[0;36mget_random_wiki_entry\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m#categories = page.categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mrelated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;31m# create a dictionary of the entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     random_wiki_entry_dict = {\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36mlinks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_links'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m       self._links = [\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0mlink\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         for link in self.__continued_query({\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_links'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m       self._links = [\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0mlink\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         for link in self.__continued_query({\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__continued_query\u001b[0;34m(self, query_params)\u001b[0m\n\u001b[1;32m    411\u001b[0m       \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_continue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m       \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wiki_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'query'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m_wiki_request\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m   \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPI_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mRATE_LIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 resp = self.send(\n\u001b[0m\u001b[1;32m    267\u001b[0m                     \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "card_deck = create_ppn_deck(50) # create a deck of 50 cards\n",
    "# show the deck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is some text that I want to summarize.\n",
      "The summary will be a few sentences long.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "# import LexRankSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "def summarize_text(text, num_sentences):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    return summary\n",
    "\n",
    "text = \"This is some text that I want to summarize. It can be as long or as short as needed. The summary will be a few sentences long.\"\n",
    "num_sentences = 2\n",
    "summary = summarize_text(text, num_sentences)\n",
    "\n",
    "for sentence in summary:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# go through the deck and summarize the text in the summary field of each card, then add the summary to the card's dictionary as a new field called \"summary_short\"\n",
    "sentence_count = 2\n",
    "for card in card_deck:\n",
    "    summary = summarize_text(card[\"summary\"][1], int(sentence_count))\n",
    "    summary_short = \"\"\n",
    "    for sentence in summary:\n",
    "        summary_short += str(sentence)\n",
    "    card[\"summary_short\"] = summary_short\n",
    "\n",
    "# show the deck\n",
    "print(f'I have created a deck of {len(card_deck)} cards')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "import sumy\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.kl import KLSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.sum_basic import SumBasicSummarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "\n",
    "# These are the available summarization methods in sumy\n",
    "summarizers = [\n",
    "    \"LsaSummarizer\", \n",
    "    \"LexRankSummarizer\", \n",
    "    \"KLSummarizer\", \n",
    "    \"TextRankSummarizer\", \n",
    "    \"SumBasicSummarizer\",\n",
    "    \"LuhnSummarizer\",\n",
    "]\n",
    "\n",
    "# This function demonstrates how to use each summarization method\n",
    "def demonstrate_summarizers(text, language=\"english\"):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "    for summarizer in summarizers:\n",
    "        summarizer = eval(summarizer)() # create an instance of the summarizer\n",
    "        summary = summarizer(parser.document, 3) # summarize the document with 3 sentences\n",
    "        print(\"====== Example: \", summarizer,\" ======\")\n",
    "\n",
    "        for sentence in summary:\n",
    "            print(sentence)\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text = \"Reddit ; stylized in all lowercase as reddit is an American social news aggregation, content rating, and discussion website. Registered users commonly referred to as Redditors submit content to the site such as links, text posts, images, and videos, which are then voted up or down by other members. Posts are organized by subject into user-created boards called communities or subreddits. Submissions with more upvotes appear towards the top of their subreddit and, if they receive enough upvotes, ultimately on the sites front page. Reddit administrators moderate the communities. Moderation is also conducted by community-specific moderators, who are not Reddit employees.As of March 2022, Reddit ranks as the 9th-most-visited website in the world and 6th most-visited website in the U.S., according to Semrush. About 4249.3% of its user base comes from the United States, followed by the United Kingdom at 7.98.2% and Canada at 5.27.8%. \"\n",
    "demonstrate_summarizers(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install pyenchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have created a deck of 50 cards\n"
     ]
    }
   ],
   "source": [
    "# clean the text of the summary field of each card by removing all special characters, replacing newlines with spaces, numbers with their word equivalent, and removing all words that are not in the english dictionary.\n",
    "\n",
    "import re\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "# import LexRankSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "# create a list of english words\n",
    "english_words = words.words()\n",
    "\n",
    "# go through the deck and summarize the text in the summary field of each card, then add the summary to the card's dictionary as a new field called \"summary_short\"\n",
    "sentence_count = 2\n",
    "for card in card_deck:\n",
    "    summary = summarize_text(card[\"summary\"][1], int(sentence_count))\n",
    "    summary_short = \"\"\n",
    "    for sentence in summary:\n",
    "        summary_short += str(sentence)\n",
    "    card[\"summary_short\"] = summary_short\n",
    "\n",
    "# show the deck\n",
    "print(f'I have created a deck of {len(card_deck)} cards')\n",
    "\n",
    "\n",
    "correct_cards = 0\n",
    "while len(card_deck) < 50:\n",
    "    # create a deck of fifty cards from the random wiki entries (non-repeating) and return the deck as a list of dictionaries\n",
    "    card_deck = create_ppn_deck(50) # create a deck of 50 cards\n",
    "    \n",
    "    # go through the deck and summarize the text in the summary field of each card, then add the summary to the card's dictionary as a new field called \"summary_short\"\n",
    "    sentence_count = 2\n",
    "    for card in card_deck:\n",
    "        summary = summarize_text(card[\"summary\"][1], int(sentence_count))\n",
    "        summary_short = \"\"\n",
    "        for sentence in summary:\n",
    "            summary_short += str(sentence)\n",
    "        card[\"summary_short\"] = summary_short\n",
    "\n",
    "    # remove any cards with words in the title that are in the banned words list\n",
    "    banned_words = ['List']\n",
    "\n",
    "    for card in card_deck:\n",
    "        for word in banned_words:\n",
    "            if word in card[\"title\"]:\n",
    "                card_deck.remove(card)\n",
    "\n",
    "    # clean the text of the summary field of each card by removing all special characters, replacing newlines with spaces, numbers with their word equivalent, and removing all words that are not in the english dictionary.\n",
    "    for card in card_deck:\n",
    "        card[\"summary_clean\"] = re.sub(r\"[^a-zA-Z0-9]+\", ' ', card[\"summary_short\"])\n",
    "        card[\"summary_clean\"] = card[\"summary_clean\"].replace(\"\\n\", \" \")\n",
    "\n",
    "    # if a card has more than 1/4 of its words in the english dictionary, then it is valid, else drop the card\n",
    "    for card in card_deck:\n",
    "        card[\"summary_clean\"] = word_tokenize(card[\"summary_clean\"])\n",
    "        card[\"summary_clean\"] = [word for word in card[\"summary_clean\"] if word in english_words]\n",
    "        if len(card[\"summary_clean\"]) < len(card[\"summary_short\"])/4:\n",
    "            card_deck.remove(card)\n",
    "\n",
    "    # use unpack_definitions on the summary_clean field to remove unusual bad words\n",
    "    for card in card_deck:\n",
    "        card[\"summary_clean\"] = unpack_definitions(card['title'],card[\"summary_clean\"])\n",
    "\n",
    "\n",
    "    # show the deck\n",
    "    print(f'I have created a deck of {len(card_deck)} cards')\n",
    "\n",
    "\n",
    "    # truncate all page summaries to be no more than 1200 characters, ending at the nearest sentence boundary. This is to prevent the summary from being too long for the flashcard.\n",
    "    for card in card_deck:\n",
    "        summary = card[\"summary_short\"]\n",
    "        if len(summary) > 1200:\n",
    "            summary = summary[:1200]\n",
    "            summary = summary[:summary.rfind('.')+1]\n",
    "            card[\"summary_short\"] = summary\n",
    "\n",
    "    # drop all cards with a summary that is less than 100 characters long\n",
    "    card_deck = [card for card in card_deck if len(card[\"summary_short\"]) > 100]\n",
    "\n",
    "    # use LexRankSummarizer to summarize the text in the summary field of each card, then add the summary to the card's dictionary as a new field called \"summary_short\"\n",
    "    for card in card_deck:\n",
    "        if card['status'] == 'good':\n",
    "            continue\n",
    "        summarizer = LexRankSummarizer() # create an instance of the summarizer\n",
    "        parser = PlaintextParser.from_string(card[\"summary\"][1], Tokenizer(\"english\"))\n",
    "        summary = summarizer(parser.document, 3) # summarize the document with 3 sentences\n",
    "        summary_short = \"\"\n",
    "        for sentence in summary:\n",
    "            summary_short += str(sentence)\n",
    "        card[\"summary_short\"] = summary_short\n",
    "        card['status'] = 'good'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have created a deck of 50 cards\n",
      "List of TCP and UDP port numbers\n",
      "Similarly, many of the official assignments refer to protocols that were never or are no longer in common use.This article lists port numbers and their associated protocols that have experienced significant uptake.\n",
      "1000\n",
      "\n",
      "Jewish Community of Vienna\n",
      "The Jewish Community of Vienna Israelitische Kultusgemeinde Wien or IKG is the body that represents Viennas Orthodox Jewish community.Throughout history, it has represented almost all of Austrias Jews, whose numbers are sufficient to form communities in only a few other cities in Austria.\n",
      "57\n",
      "\n",
      "Timeline of Russian interference in the 2016 United States elections\n",
      "This is a timeline of events related to alleged Russian interference in the 2016 United States elections.It includes events described in investigations into suspected inappropriate links between associates of Donald Trump and Russian officials until July 2016, with July 2016 through election day November 8, 2016, following.\n",
      "1133\n",
      "\n",
      "Radha\n",
      "She is worshiped as the deitydess of love, tenderness, comrear endion, and devotion.Radha is also described as the feminine form of Krishna himself.\n",
      "644\n",
      "\n",
      "Don Quixote\n",
      "He recruits a simple farmer, Sancho Panza, as his squire, who often employs a unique, earthy wit in dealing with Don Quixotes rhetorical monologues on kracial slurhthood, already considered old-fashioned at the time, and representing the most droll realism in contrast to his masters idealism.After the successful French Revolution, it was better known for its presumed central ethic that in some ways individuals can be intelligent while their society is quite fanciful and was seen as a fascinating, enchanting or disenchanting lady pillowsk in this dynamic and for among lady pillowsks.\n",
      "294\n",
      "\n",
      "Wiktionary\n",
      "Wiktionary UK: WIK-sh-nr-ee, US: WIK-sh-nerr-ee, rhyming with dictionary is a multilingual, web-based project to create a free content dictionary of terms including words, phrases, proverbs, linguistic reconstructions, etc.Because Wiktionary is not limited by print space considerations, most of Wiktionarys language editions provide definitions and translations of terms from many languages, and some editions offer additional information typically found in thesauri.\n",
      "217\n",
      "\n",
      "Reddit\n",
      "In July 2017, Reddit raised $200 million for a $1.8 billion valuation, with Advance Publications remaining the majority stakeholder.The company then reportedly filed for an IPO in December 2021 with a valuation of 15 billion dollars.\n",
      "485\n",
      "\n",
      "Anushka Manchanda\n",
      "Anushka Manchanda aka Kiss Nuka born 11 February 1984 is a singer, music producer, composer, creative entrepreneur, actor, activist, and former VJ of Indian origin.She came to prominence as a member of the Indipop girl group Viva!.\n",
      "210\n",
      "\n",
      "History of Transnistria\n",
      "This is the history of Transnistria, officially the Pridnestrovian Moldavian Republic PMR, is an unrecognised breakaway state that is internationally recognised as part of Moldova.See also the history of Europe.\n",
      "307\n",
      "\n",
      "Mirza Masroor Ahmad\n",
      "He was elected on 22 April 2003, three days after the death of his predecessor Mirza Tahir Ahmad.Under his leadership the communitys global satellite TV network MTA International, launched by his predecessor, has expanded into several further affiliated TV channels, social media and radio stations to provide transmission in different languages.\n",
      "159\n",
      "\n",
      "List of band name etymologies\n",
      "This is a list of band names, with their name origins explained and referenced with reliable sources.\n",
      "1161\n",
      "\n",
      "List of TCP and UDP port numbers\n",
      "Similarly, many of the official assignments refer to protocols that were never or are no longer in common use.This article lists port numbers and their associated protocols that have experienced significant uptake.\n",
      "1000\n",
      "\n",
      "Timeline of Russian interference in the 2016 United States elections\n",
      "This is a timeline of events related to alleged Russian interference in the 2016 United States elections.It includes events described in investigations into suspected inappropriate links between associates of Donald Trump and Russian officials until July 2016, with July 2016 through election day November 8, 2016, following.\n",
      "1133\n",
      "\n",
      "Iranâ€“Iraq War\n",
      "After pushing Iraqi forces back to the pre-war border lines, Iran rejected United Nations Security Council Resolution 514 and launched an invasion of Iraq.The conflict has been compared to World War I in terms of the tactics used by both sides, including large-scale trench warfare with barbed wire stretched across fortified defensive lines, manned machine-gun posts, bayonet charges, Iranian human wave attacks, Iraqs extensive use of chemical weapons, and deliberate attacks on civilian targets.\n",
      "1718\n",
      "\n",
      "Architectural model\n",
      "An architectural model is a type of scale model made to study aspects of an architectural design or to communicate design intent.They can be made from a variety of materials such as paper, plaster, plastic, resin, wood, grear end and metal.\n",
      "444\n",
      "\n",
      "John Peel (writer)\n",
      "John Peel born 1954 is a British writer, best known for his TV series tie-in novels and novelisations.He has written under several pseudonyms, including John Vincent and Nicholas Adams.\n",
      "60\n",
      "\n",
      "Reddit\n",
      "In July 2017, Reddit raised $200 million for a $1.8 billion valuation, with Advance Publications remaining the majority stakeholder.The company then reportedly filed for an IPO in December 2021 with a valuation of 15 billion dollars.\n",
      "485\n",
      "\n",
      "Radha\n",
      "She is worshiped as the deitydess of love, tenderness, comrear endion, and devotion.Radha is also described as the feminine form of Krishna himself.\n",
      "644\n",
      "\n",
      "Sardinian language\n",
      "Sardinian or Sard sardu sadu, limba sarda limba zada or lngua sarda liwa zada is a Romance language spoken by the Sardinians on the Western Mediterranean island of Sardinia.Many Romance linguists consider it the language that is closest to Latin among all its genealogical descendants.\n",
      "701\n",
      "\n",
      "Spring, Texas\n",
      "Spring is a census-designated place CDP within the extraterritorial juripenistion of Houston in Harris County, Texas, United States, part of the HoustonThe WoodlandsSugar Land metropolitan area.While the name Spring is popularly apeopleied to a large area of northern Harris County and a smaller area of southern Montgomery County, the original town of Spring, now known as Old Town Spring, is located at the intersection of Spring-Cypress and Hardy roads and encomrear ends a relatively small area of perhaps 1 square kilometer 0.39 sq mi.\n",
      "407\n",
      "\n",
      "List of songs recorded by KK\n",
      "KK 19682022 was an Indian playback singer.He has been a prominent singer in Hindi, Tamil, Telugu, Kannada, Malayalam, Marathi, Bengali and Gujarati language films.\n",
      "779\n",
      "\n",
      "List of band name etymologies\n",
      "This is a list of band names, with their name origins explained and referenced with reliable sources.\n",
      "1161\n",
      "\n",
      "John Peel (writer)\n",
      "John Peel born 1954 is a British writer, best known for his TV series tie-in novels and novelisations.He has written under several pseudonyms, including John Vincent and Nicholas Adams.\n",
      "60\n",
      "\n",
      "List of youngest killers\n",
      "This is a list of youngest killers.Individuals in this list are documented to be age 17 or younger.\n",
      "423\n",
      "\n",
      "Rashtriya Swayamsevak Sangh\n",
      "It drew initial inspiration from European right-wing groups during World War II, such as the Italian Fascist Party.Gradually, RSS grew into a prominent Hindu nationalist umbrella organisation, spawning several affiliated organisations that established numerous schools, charities, and clubs to spread its ideological beliefs.The RSS was banned once during British rule, and then thrice by the post-independence Indian government, first in 1948 when Nathuram Godse, an erstwhile member of RSS, asrear endinated Mahatma Gandhi; then during The Emergency 19751977; and for a third time after the demolition of Babri Masjid in 1992.\n",
      "1155\n",
      "\n",
      "List of operations conducted by Delta Force\n",
      "This is an incomplete list of operations conducted by Delta Force.\n",
      "228\n",
      "\n",
      "Havana\n",
      "Old Havana was declared a UNESCO World Heritage Site in 1982.The city is also noted for its history, culture, architecture and monuments.\n",
      "1100\n",
      "\n",
      "Wiktionary\n",
      "Wiktionary UK: WIK-sh-nr-ee, US: WIK-sh-nerr-ee, rhyming with dictionary is a multilingual, web-based project to create a free content dictionary of terms including words, phrases, proverbs, linguistic reconstructions, etc.Because Wiktionary is not limited by print space considerations, most of Wiktionarys language editions provide definitions and translations of terms from many languages, and some editions offer additional information typically found in thesauri.\n",
      "217\n",
      "\n",
      "List of Weekly Idol episodes\n",
      "For its first season, the show was hosted by comedian Jeong Hyeong-don and rapper Defconn.The second season, which debuted on April 11, 2018, was hosted by former Roora member Lee Sang-min and comedians Yoo Se-yoon & Kim Shin-young.The third season, which debuted on January 9, 2019, is hosted by comedians Jo Se-ho & Nam Chang-hee and ZE:As Hwang Kwang-hee.\n",
      "418\n",
      "\n",
      "List of TCP and UDP port numbers\n",
      "Similarly, many of the official assignments refer to protocols that were never or are no longer in common use.This article lists port numbers and their associated protocols that have experienced significant uptake.\n",
      "1000\n",
      "\n",
      "Thibodeau\n",
      "Notable people with the surname include:Carter Thibodeau, from Under the Dome by Stephen King Denise and Henry Thibodeau, from Olive Kitteridge by Elizabeth Strout\n",
      "20\n",
      "\n",
      "Tagline\n",
      "Many tagline slogans are reiterated phrases associated with an individual, social group, or product.Some taglines are successful enough to warrant inclusion in popular culture.\n",
      "153\n",
      "\n",
      "Sardinian language\n",
      "Sardinian or Sard sardu sadu, limba sarda limba zada or lngua sarda liwa zada is a Romance language spoken by the Sardinians on the Western Mediterranean island of Sardinia.Many Romance linguists consider it the language that is closest to Latin among all its genealogical descendants.\n",
      "701\n",
      "\n",
      "List of U.S. state and territory nicknames\n",
      "The following is a table of U.S. state, federal district and territory nicknames, including officially adopted nicknames and other traditional nicknames for the 50 U.S. states, the U.S. federal district, as well as five U.S. territories.\n",
      "534\n",
      "\n",
      "Antichrist\n",
      "In Christian eschatology, the Antireligious figure refers to people prophesied by the Bible to oppose Jesus Christ and substitute themselves in Christs place before the Second Coming.In Matthew chapter 24 and Mark chapter 13, Jesus alerts his disciples not to be deceived by the false prophets, who will claim themselves as being Christ, performing great signs and wonders.\n",
      "931\n",
      "\n",
      "List of fictional robots and androids\n",
      "The word robot itself comes from a work of fiction, Karel apeks play, R.U.R.This list is intended for all fictional computers which are described as existing in a humanlike or mobile form.\n",
      "1941\n",
      "\n",
      "Iranâ€“Iraq War\n",
      "After pushing Iraqi forces back to the pre-war border lines, Iran rejected United Nations Security Council Resolution 514 and launched an invasion of Iraq.The conflict has been compared to World War I in terms of the tactics used by both sides, including large-scale trench warfare with barbed wire stretched across fortified defensive lines, manned machine-gun posts, bayonet charges, Iranian human wave attacks, Iraqs extensive use of chemical weapons, and deliberate attacks on civilian targets.\n",
      "1718\n",
      "\n",
      "Timeline of Russian interference in the 2016 United States elections\n",
      "This is a timeline of events related to alleged Russian interference in the 2016 United States elections.It includes events described in investigations into suspected inappropriate links between associates of Donald Trump and Russian officials until July 2016, with July 2016 through election day November 8, 2016, following.\n",
      "1133\n",
      "\n",
      "Architectural model\n",
      "An architectural model is a type of scale model made to study aspects of an architectural design or to communicate design intent.They can be made from a variety of materials such as paper, plaster, plastic, resin, wood, grear end and metal.\n",
      "444\n",
      "\n",
      "The Witch of Konotop\n",
      "The Witch of Konotop Ukrainian:   is a satirical fiction story by Ukrainian writer Hryhorii Kvitka-Osnovianenko written in 1833 and published in 1837 in his second lady pillowsk of Little Russian Ukrainian stories.The work consists of 14 chapters and an epilogue; each section begins with the words sad and gloomy.\n",
      "14\n",
      "\n",
      "Comparison of BitTorrent clients\n",
      "Opera 12, a web browser, can also transfer files via BitTorrent.In 2013 Thunder Networking Technologies publicly revealed that some of their employees surreptitiously distributed a Trojan horse with certain releases of Xunlei, the companys BitTorrent-ready download manager.\n",
      "190\n",
      "\n",
      "Spies Like Us\n",
      "Spies Like Us is a 1985 American spy comedy film directed by John Landis, and starring Chevy Chase, Dan Aykroyd, Steve Forrest and Donna Dixon.Other cameos include directors Terry Gilliam, Sam Raimi, Costa-Gavras, Martin Brest, Frank Oz, and Joel Coen, musician B.B.\n",
      "196\n",
      "\n",
      "URL shortening\n",
      "This is because the URL shortener can redirect to just about any web domain, even malicious ones.So, although disguising of the underlying address may be desired for legitimate business or personal reasons, it is open to abuse.\n",
      "98\n",
      "\n",
      "Piracy in the Atlantic World\n",
      "Piracy was a phenomenon that was not limited to the Caribbean region.Golden Age pirates roamed off the coast of North America, Africa and the Caribbean.\n",
      "440\n",
      "\n",
      "Multiculturalism\n",
      "On a smaller scale this can occur artificially when a juripenistion is established or expanded by amalgamating areas with two or more different cultures e.g. French Canada and English Canada.Multiculturalism as a political philosophy involves ideologies and policies which vary widely.\n",
      "1169\n",
      "\n",
      "Massimiliano Alajmo\n",
      "rear endimiliano Alajmo born 6 May 1974 is an Italian chef.In 2002, at the age of 28, he became the youngest chef in history to be awarded three stars by the Michelin Guide.\n",
      "21\n",
      "\n",
      "Don Quixote\n",
      "He recruits a simple farmer, Sancho Panza, as his squire, who often employs a unique, earthy wit in dealing with Don Quixotes rhetorical monologues on kracial slurhthood, already considered old-fashioned at the time, and representing the most droll realism in contrast to his masters idealism.After the successful French Revolution, it was better known for its presumed central ethic that in some ways individuals can be intelligent while their society is quite fanciful and was seen as a fascinating, enchanting or disenchanting lady pillowsk in this dynamic and for among lady pillowsks.\n",
      "294\n",
      "\n",
      "Timeline of Extinction Rebellion actions\n",
      "Extinction Rebellion has taken a variety of actions since 2018 in the UK, USA, Australia and elsewhere.\n",
      "256\n",
      "\n",
      "Sherbrooke Hussars\n",
      "The Sherbrooke Hussars is a Primary Reserve armoured regiment of the Canadian Forces and perpetuates the Sherbrooke Fusilier Regiment of the Second World War.\n",
      "225\n",
      "\n",
      "Mac Davis\n",
      "Morris Mac Davis January 21, 1942  September 29, 2020 was an American country music singer, songwriter, and actor.A subsequent solo career in the 1970s produced hits such as Baby, Dont Get Hooked on Me.\n",
      "160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'I have created a deck of {len(card_deck)} cards')\n",
    "for card in card_deck:\n",
    "    print(card[\"title\"])\n",
    "    print(card[\"summary_short\"])\n",
    "    print(card[\"related\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the deck to a json file by combining the card dictionaries into a json file format.\n",
    "\n",
    "import json\n",
    "\n",
    "with open('ppn_deck.json', 'w') as outfile:\n",
    "    json.dump(card_deck, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<word> <word> sometimes also called Volxmusik or Tradimix; English for New folk music describes the crossover mix of traditional German folk music <word> with newer genres such as jazz, contemporary folk, electronic music, and/or rock.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "deck = [{\n",
    "        \"title\": \"Neue Volksmusik\",\n",
    "        \"summary\": [\n",
    "            \"Neue Volksmusik\",\n",
    "            \"Neue Volksmusik sometimes also called Volxmusik or Tradimix; English for New folk music describes the crossover mix of traditional German folk music Volksmusik with newer genres such as jazz, contemporary folk, electronic music, and/or rock.\"\n",
    "        ],\n",
    "        \"related\": 23\n",
    "    }]\n",
    "\n",
    "card = deck[0]\n",
    "title = card[\"title\"]\n",
    "summary = card[\"summary\"][1]\n",
    "\n",
    "# Split the summary into a list of sentences\n",
    "sentences = nltk.sent_tokenize(summary)\n",
    "\n",
    "# Split the title into a list of words\n",
    "title_words = title.split()\n",
    "\n",
    "# Iterate through the sentences and reword if necessary\n",
    "reworded_sentences = []\n",
    "for sentence in sentences:\n",
    "    # Check for words from the title in the sentence\n",
    "    for word in title_words:\n",
    "        if word in sentence:\n",
    "            # Reword the sentence to avoid using the word\n",
    "            sentence = sentence.replace(word, \"<word>\")\n",
    "    reworded_sentences.append(sentence)\n",
    "\n",
    "# Join the reworded sentences into a single string\n",
    "reworded_summary = \" \".join(reworded_sentences)\n",
    "print(reworded_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/grahamwaters/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slogan 'this (slogan) this (slogan) this (slogan)' was used by the Conservative Party in the 2019 United Kingdom general election. It was intended to convey the party's commitment to taking the UK out of the European Union.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "deck = [{\n",
    "        \"title\": \"Get Brexit Done\",\n",
    "        \"summary\": [\n",
    "            \"Get Brexit Done\",\n",
    "            \"The slogan 'Get Brexit Done' was used by the Conservative Party in the 2019 United Kingdom general election. It was intended to convey the party's commitment to taking the UK out of the European Union.\"\n",
    "        ],\n",
    "        \"related\": 23\n",
    "    }]\n",
    "\n",
    "card = deck[0]\n",
    "title = card[\"title\"]\n",
    "summary = card[\"summary\"][1]\n",
    "\n",
    "# Split the summary into a list of sentences\n",
    "sentences = nltk.sent_tokenize(summary)\n",
    "\n",
    "# Split the title into a list of words\n",
    "title_words = title.split()\n",
    "\n",
    "# Iterate through the sentences and reword if necessary\n",
    "reworded_sentences = []\n",
    "for sentence in sentences:\n",
    "    # Check for words from the title in the sentence\n",
    "    for word in title_words:\n",
    "        if word in sentence:\n",
    "            # Reword the sentence to avoid using the word\n",
    "            sentence = sentence.replace(word, \"this (slogan)\")\n",
    "    reworded_sentences.append(sentence)\n",
    "\n",
    "# Join the reworded sentences into a single string\n",
    "reworded_summary = \" \".join(reworded_sentences)\n",
    "print(reworded_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
