{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing card_images folder...\n",
      "Initialized process, and ready to generate physical cards...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import textwrap\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.corpus import stopwords\n",
    "# PlaintextParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "# LexRankSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "# LsaSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "# define Tokenizer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "# define Stemmer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "# define language\n",
    "pytrend = TrendReq(hl='en-US', tz=360)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "# with open(\"ppn_deck_cleaned.json\", \"w\") as write_file:\n",
    "#     json.dump(card_deck, write_file, indent=4)\n",
    "\n",
    "# read card_deck from ppn_deck.json file\n",
    "with open(\"ppn_deck.json\", \"r\") as read_file:\n",
    "    card_deck = json.load(read_file)\n",
    "\n",
    "\n",
    "# clear the card_images folder\n",
    "print(\"Clearing card_images folder...\")\n",
    "for filename in os.listdir(\"card_images\"):\n",
    "    os.remove(os.path.join(\"card_images\", filename))\n",
    "\n",
    "\n",
    "\n",
    "def summarize_text(text, num_sentences):\n",
    "    \"\"\"\n",
    "    Summarize the given text using the LSA or LexRank summarization algorithms and return the summary as a string\n",
    "    \"\"\"\n",
    "    # create a PlaintextParser object to parse the text\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    # choose a summarization algorithm\n",
    "    # algorithm = LsaSummarizer()\n",
    "    algorithm = LexRankSummarizer()\n",
    "\n",
    "    # summarize the text and return the summary as a string\n",
    "    summary = algorithm(parser.document, num_sentences)\n",
    "    summary_text = \"\\n\".join([str(sentence) for sentence in summary])\n",
    "\n",
    "    return summary_text\n",
    "\n",
    "\n",
    "\n",
    "def get_google_trends_score(title):\n",
    "    # get the google trends score for the query (for all time)\n",
    "    # this is to determine how popular the topic is\n",
    "    title = str(title)\n",
    "    pytrend.build_payload(kw_list=[title], timeframe='all')\n",
    "    interest_over_time_df = pytrend.interest_over_time()\n",
    "    # get the score for the last 12 months, and return the mean\n",
    "    recent_score = interest_over_time_df[title][-12:].mean()\n",
    "    # get the score for all time\n",
    "    all_time_score = interest_over_time_df[title].mean()\n",
    "    # return the higher of the two scores\n",
    "    return max(recent_score, all_time_score)\n",
    "\n",
    "def generate_card(title, definition, points):\n",
    "    # determine the font size based on the length of the definition\n",
    "    # font_size = int(len(definition) / 20)\n",
    "    font_size = max(30, int(len(definition) / 20))\n",
    "    # create the image and draw objects\n",
    "    # set the canvas size to 8.5 cm by 5.5 cm\n",
    "    image = Image.new('RGB', (550, 850), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # select a font and draw the title in a rectangle\n",
    "    font = ImageFont.truetype('./fonts/Menlo.ttc', 15)\n",
    "    draw.rectangle([(10, 10), (540, 50)], fill='lightgrey')\n",
    "    draw.text((20, 20), title, fill=(0, 0, 0), font=font)\n",
    "\n",
    "    # draw the definition in a rectangle, and soft wrap the text. Don't exceed 40 characters per line. \n",
    "    # wrapped_definition = textwrap.wrap(definition, width=40)\n",
    "    definition = str(definition) if isinstance(definition, str) else definition[0]\n",
    "    wrapped_definition = textwrap.fill(definition, width=80)\n",
    "    wrapped_definition_str = \"\\n\".join(wrapped_definition)\n",
    "    font = ImageFont.truetype('./fonts/Menlo.ttc', font_size)\n",
    "    draw.text((20, 70), wrapped_definition, fill=(0, 0, 0))\n",
    "\n",
    "    # draw a circle around the point value\n",
    "    draw.ellipse([(520, 820), (540, 840)], fill='lightgreen')\n",
    "    # draw the point value\n",
    "\n",
    "    font = ImageFont.truetype('./fonts/Menlo.ttc', font_size + 1)\n",
    "    draw.text((525, 825), str(points), fill=(0, 0, 0))\n",
    "\n",
    "    # save the image\n",
    "    image.save('./card_images/{}.png'.format(len(os.listdir('./card_images/'))))\n",
    "\n",
    "def generate_physical_cards():\n",
    "    #^ Example usage\n",
    "    card = random.choice(card_deck)\n",
    "    print(card)\n",
    "    summary = card['summary'][1] if isinstance(card['summary'], list) else card['summary']\n",
    "    # summarize the definition with the summarize function\n",
    "    summary = summarize_text(summary, 2) if isinstance(summary, str) else summary # if the summary is a list, then it's already been summarized\n",
    "    if isinstance(summary, str):\n",
    "        summary = summarize_text(summary, 2)\n",
    "    if isinstance(summary, list):\n",
    "        summary = ' '.join(summary)\n",
    "    #?points = len(set(summary.split()) - set(stopwords.words('english'))) # all words not in the stopword list\n",
    "    points = len(set(summary.split())) # all words\n",
    "    generate_card(str(card['title']), summary, points=points)\n",
    "    # generate_card('test title', 'test definition', 10)\n",
    "\n",
    "    # iterate through each card and generate a card image for it\n",
    "    # note: if the card has been summarized already, then the summary will be a list, so we need to get the first element of the list\n",
    "    for card in tqdm(card_deck):\n",
    "        title = card['title']\n",
    "        summary = card['summary'][1] if isinstance(card['summary'], list) else card['summary']\n",
    "        # summarize the definition with the summarize function\n",
    "        summary = summarize_text(summary, 2) if isinstance(summary, str) else summary # if the summary is a list, then it's already been summarized\n",
    "        if isinstance(summary, str):\n",
    "            summary = summarize_text(summary, 2)\n",
    "        if isinstance(summary, list):\n",
    "            summary = ' '.join(summary)\n",
    "        # make the point value the number of unique words in the summary (unique to the card compared to other cards)\n",
    "        #?points = len(set(summary.split()) - set(stopwords.words('english'))) # all words not in the stopword list\n",
    "        points = len(set(summary.split())) # all words\n",
    "        # generate the card\n",
    "        generate_card(str(card['title']), summary, points=points) # get_google_trends_score(card['title'])\n",
    "        #!print(f'Found a score of {get_google_trends_score(card[\"title\"])} for {card[\"title\"]}')\n",
    "\n",
    "print(\"Initialized process, and ready to generate physical cards...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Guerrilla Zoo', 'summary': ['Guerrilla Zoo', 'Guerrilla Zoo is a contemporary arts organisation formed in 2004 by founder and creative director James Elphick. The group produce a variety of creative events from experiential environments, live concerts, festivals, immersive theatre, art exhibitions, arts awards, parties and masquerade balls.'], 'related': 24, 'summary_short': \"['Guerrilla Zoo', 'Guerrilla Zoo is a contemporary arts organisation formed in 2004 by founder and creative director James Elphick.The group produce a variety of creative events from experiential environments, live concerts, festivals, immersive theatre, art exhibitions, arts awards, parties and masquerade balls.']\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2521/2521 [00:43<00:00, 57.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generate_physical_cards()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'links_on_page'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_84303/1640415744.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Get a list of the links_on_page values from the card_deck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlinks_on_page_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'links_on_page'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcard\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcard_deck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Fit the scaler on the links_on_page values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_84303/1640415744.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Get a list of the links_on_page values from the card_deck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlinks_on_page_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'links_on_page'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcard\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcard_deck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Fit the scaler on the links_on_page values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'links_on_page'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Get a list of the links_on_page values from the card_deck\n",
    "links_on_page_values = [card['links_on_page'] for card in card_deck]\n",
    "\n",
    "# Fit the scaler on the links_on_page values\n",
    "scaler.fit(links_on_page_values)\n",
    "\n",
    "# Use the scaler to transform the links_on_page values\n",
    "scaled_links_on_page = scaler.transform(links_on_page_values)\n",
    "\n",
    "# Update the points value for each card in the card_deck with the scaled links_on_page value\n",
    "for i, card in enumerate(card_deck):\n",
    "    card['points'] = int(scaled_links_on_page[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
