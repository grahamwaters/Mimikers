{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing card_images folder...\n",
      "Initialized process, and ready to generate physical cards...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import textwrap\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.corpus import stopwords\n",
    "# PlaintextParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "# LexRankSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "# LsaSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "# define Tokenizer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "# define Stemmer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "# define language\n",
    "pytrend = TrendReq(hl='en-US', tz=360)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "# with open(\"ppn_deck_cleaned.json\", \"w\") as write_file:\n",
    "#     json.dump(card_deck, write_file, indent=4)\n",
    "\n",
    "# read card_deck from ppn_deck.json file\n",
    "with open(\"ppn_deck.json\", \"r\") as read_file:\n",
    "    card_deck = json.load(read_file)\n",
    "\n",
    "\n",
    "# clear the card_images folder\n",
    "print(\"Clearing card_images folder...\")\n",
    "for filename in os.listdir(\"card_box\"):\n",
    "    os.remove(os.path.join(\"card_box\", filename))\n",
    "\n",
    "\n",
    "\n",
    "def summarize_text(text, num_sentences):\n",
    "    \"\"\"\n",
    "    Summarize the given text using the LSA or LexRank summarization algorithms and return the summary as a string\n",
    "    \"\"\"\n",
    "    # create a PlaintextParser object to parse the text\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    # choose a summarization algorithm\n",
    "    # algorithm = LsaSummarizer()\n",
    "    algorithm = LexRankSummarizer()\n",
    "\n",
    "    # summarize the text and return the summary as a string\n",
    "    summary = algorithm(parser.document, num_sentences)\n",
    "    summary_text = \"\\n\".join([str(sentence) for sentence in summary])\n",
    "\n",
    "    return summary_text\n",
    "\n",
    "\n",
    "\n",
    "def get_google_trends_score(title):\n",
    "    # get the google trends score for the query (for all time)\n",
    "    # this is to determine how popular the topic is\n",
    "    title = str(title)\n",
    "    pytrend.build_payload(kw_list=[title], timeframe='all')\n",
    "    interest_over_time_df = pytrend.interest_over_time()\n",
    "    # get the score for the last 12 months, and return the mean\n",
    "    recent_score = interest_over_time_df[title][-12:].mean()\n",
    "    # get the score for all time\n",
    "    all_time_score = interest_over_time_df[title].mean()\n",
    "    # return the higher of the two scores\n",
    "    return max(recent_score, all_time_score)\n",
    "\n",
    "def generate_card(title, definition, points, name=None):\n",
    "    # if the font is 20 then the max width of the text is 40 characters. Use this to determine how large the title should be.\n",
    "    image = Image.new('RGB', (550, 850), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    # the title is wrapped to 40 characters, so the height of the rectangle is the number of characters * 20 (the height of the font)\n",
    "    title_size = 20\n",
    "    font_title = ImageFont.truetype('./fonts/Menlo.ttc', title_size)\n",
    "    font_description = ImageFont.truetype('./fonts/Menlo.ttc', 20)\n",
    "    font_points = ImageFont.truetype('./fonts/Menlo.ttc', 18)\n",
    "    title_wrapped = textwrap.wrap(title, width=40)\n",
    "    # draw the title centered horizontally, and 30 pixels from the top. The title is wrapped to 40 characters, so the height of the rectangle is the number of characters * 20 (the height of the font)\n",
    "\n",
    "    title_rectangle_height = len(title_wrapped) * 20\n",
    "    draw.rectangle([(10, 10), (540, 10 + title_rectangle_height)], fill='lightblue')\n",
    "    y_text = 20\n",
    "    for line in title_wrapped:\n",
    "        draw.text((270, y_text), line, fill=(0, 0, 0), font=font_title, anchor='mm')\n",
    "        y_text += 20\n",
    "    # draw the definition left justified, and 10 pixels from the the bottom of the title rectangle. The definition is wrapped to 40 characters, so the height of the rectangle is the number of characters / 40 * 20 (the height of the font).\n",
    "    definition_wrapped = textwrap.wrap(definition, width=40)\n",
    "    definition_rectangle_height = len(definition_wrapped) * 20\n",
    "    draw.rectangle([(10, 10 + title_rectangle_height + 10), (540, 10 + title_rectangle_height + 10 + definition_rectangle_height)], fill='white')\n",
    "    y_text = 10 + title_rectangle_height + 20\n",
    "    for line in definition_wrapped:\n",
    "        draw.text((10, y_text), line, fill=(0, 0, 0), font=font_description, anchor='lm')\n",
    "        y_text += 20\n",
    "\n",
    "\n",
    "\n",
    "    # draw the points at the bottom of the card centered horizontally, and 20 pixels from the bottom\n",
    "    # draw the rectangle around the points, with a light green background, add 10 pixels to the height of the rectangle to make it a little bigger and center the text within the rectangle vertically\n",
    "    draw.rectangle([(10, 850 - 30 - 10), (540, 850 - 10)], fill='lightgreen')\n",
    "    # draw the text in the rectangle\n",
    "    draw.text((270, 850 - 30 - 5), str(points), fill=(0, 0, 0), font=font_points, anchor='mm') # anchor='mm' centers the text horizontally and vertically\n",
    "    # save the image with the name of the card if not None\n",
    "    if name is not None:\n",
    "        image.save('./card_box/{}.png'.format(name)) # save the image with the name of the card, if it's not None\n",
    "    else:\n",
    "        image.save('./card_box/{}.png'.format(len(os.listdir('./card_box/')))) # save the image with the name of the number of images in the folder\n",
    "\n",
    "def generate_physical_cards():\n",
    "    #^ Example usage\n",
    "    card = random.choice(card_deck)\n",
    "    print(card)\n",
    "    summary = card['summary'][1] if isinstance(card['summary'], list) else card['summary']\n",
    "    # summarize the definition with the summarize function\n",
    "    summary = summarize_text(summary, 2) if isinstance(summary, str) else summary # if the summary is a list, then it's already been summarized\n",
    "    if isinstance(summary, str):\n",
    "        summary = summarize_text(summary, 2)\n",
    "    if isinstance(summary, list):\n",
    "        summary = ' '.join(summary)\n",
    "    #?points = len(set(summary.split()) - set(stopwords.words('english'))) # all words not in the stopword list\n",
    "    points = len(set(summary.split())) # all words\n",
    "    generate_card(str(card['title']), summary, points=points)\n",
    "    # generate_card('test title', 'test definition', 10)\n",
    "\n",
    "    # iterate through each card and generate a card image for it\n",
    "    # note: if the card has been summarized already, then the summary will be a list, so we need to get the first element of the list\n",
    "    for card in tqdm(card_deck):\n",
    "        title = card['title']\n",
    "        summary = card['summary'][1] if isinstance(card['summary'], list) else card['summary']\n",
    "        # summarize the definition with the summarize function\n",
    "        summary = summarize_text(summary, 2) if isinstance(summary, str) else summary # if the summary is a list, then it's already been summarized\n",
    "        if isinstance(summary, str):\n",
    "            summary = summarize_text(summary, 2)\n",
    "        if isinstance(summary, list):\n",
    "            summary = ' '.join(summary)\n",
    "        # make the point value the number of unique words in the summary (unique to the card compared to other cards)\n",
    "        #?points = len(set(summary.split()) - set(stopwords.words('english'))) # all words not in the stopword list\n",
    "        points = len(set(summary.split())) # all words\n",
    "        # generate the card\n",
    "        generate_card(str(card['title']), summary, points=points) # get_google_trends_score(card['title'])\n",
    "        #!print(f'Found a score of {get_google_trends_score(card[\"title\"])} for {card[\"title\"]}')\n",
    "\n",
    "print(\"Initialized process, and ready to generate physical cards...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Kokotoni Wilf', 'summary': ['Kokotoni Wilf', 'Kokotoni Wilf, Kokotoni Wilf is an action-adventure game released by Elite Systems in 1984 for the Amstrad CPC, Commodore 64, and ZX Spectrum home computers. The game was inspired by Jet Set Willy.'], 'related': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3795/3795 [01:35<00:00, 39.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generate_physical_cards()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
