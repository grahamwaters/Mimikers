{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install html2image\n",
    "runcode = True # set to True to run code that queries wikipedia for more cards.\n",
    "restarting_requested = False # set to True to restart the kernel and run the code again, will set the json file to blank, so you can start over.\n",
    "reset_cardbox = True # set to True to reset the cardbox, will remove all cards from the cardbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh (reset) the ppn_deck.json file with one card only (the first card)\n",
    "# this is useful when you want to start over with a new deck\n",
    "# you can also use this to create a new deck from scratch\n",
    "import json\n",
    "if restarting_requested:\n",
    "    starter = [{\n",
    "            \"title\": \"Michael Buffer\",\n",
    "            \"summary\": [\n",
    "                \"Michael Buffer\",\n",
    "                \"Michael Buffer born November 2, 1944 is an American ring announcer or MC for boxing, professional wrestling, and National Football League matches. He is known for his trademarked catchphrase: Lets get ready to rumble!\"\n",
    "            ],\n",
    "            \"related\": 174\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Clapton is God\",\n",
    "            \"summary\": [\n",
    "                \"Clapton is God\",\n",
    "                \"Clapton is God is a 1960s meme referencing the English guitarist Eric Clapton. The line was popularised after being spray-painted on a wall in London during the mid-1960s, when Clapton was a member of the Yardbirds and John Mayall & the Bluesbreakers, creating the cult of the guitar hero.\"\n",
    "            ],\n",
    "            \"related\": 168\n",
    "        }\n",
    "    ]\n",
    "    with open('ppn_deck.json', 'w') as f:\n",
    "        json.dump(starter, f)\n",
    "else:\n",
    "    with open('ppn_deck.json', 'r') as f:\n",
    "        starter = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/grahamwaters/Library/Mobile Documents/com~apple~CloudDocs/Mimikers/wiki_monikers.py:186: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  urls_master = pd.read_csv(\"./peoplelinks.csv\", error_bad_lines=False)\n",
      "Skipping line 45: expected 2 fields, saw 8\n",
      "Skipping line 213: expected 2 fields, saw 3\n",
      "Skipping line 299: expected 2 fields, saw 3\n",
      "Skipping line 313: expected 2 fields, saw 3\n",
      "Skipping line 414: expected 2 fields, saw 3\n",
      "Skipping line 520: expected 2 fields, saw 4\n",
      "Skipping line 529: expected 2 fields, saw 4\n",
      "Skipping line 623: expected 2 fields, saw 3\n",
      "Skipping line 712: expected 2 fields, saw 4\n",
      "Skipping line 733: expected 2 fields, saw 3\n",
      "Skipping line 738: expected 2 fields, saw 4\n",
      "Skipping line 962: expected 2 fields, saw 3\n",
      "Skipping line 980: expected 2 fields, saw 3\n",
      "Skipping line 985: expected 2 fields, saw 3\n",
      "Skipping line 988: expected 2 fields, saw 3\n",
      "Skipping line 993: expected 2 fields, saw 3\n",
      "Skipping line 999: expected 2 fields, saw 3\n",
      "Skipping line 1053: expected 2 fields, saw 3\n",
      "\n",
      "3782\n",
      "card 3783: Edward VII: \n",
      "\tEdward VII, Edward VII Albert Edward; 9 November 1841 6 May ...\n",
      "/opt/anaconda3/envs/groupme/lib/python3.9/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /opt/anaconda3/envs/groupme/lib/python3.9/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n",
      "card 3784: John Zegrus: \n",
      "\tJohn Zegrus, John Allen Kuchar Zegrus , Jon Aren Kacch Jgura...\n",
      "card 3785: Vena comitans: \n",
      "\tVena comitans, Vena comitans is Latin for accompanying vein....\n",
      "card 3786: Grubhub: \n",
      "\tGrubhub, Grubhub Inc. is an American online and mobile prepa...\n",
      "card 3787: Violet Turner: \n",
      "\tViolet Turner, Dr. Violet Marianne Turner is a fictional cha...\n",
      "card 3788: Forbes Top 40: \n",
      "\tForbes Top 40, The Forbes Top 40 was an annual list of 40 hi...\n",
      "card 3789: Seth Brundle: \n",
      "\tSeth Brundle, Dr. Seth Brundle, also known as Brundlefly, is...\n",
      "card 3790: Nelson Mandela: \n",
      "\tNelson Mandela, Nelson Rolihlahla Mandela ; Xhosa: xolaa man...\n",
      "card 3791: Notoscopelus caudispinosus: \n",
      "\tNotoscopelus caudispinosus, Notoscopelus caudispinosus is a ...\n",
      "card 3792: Ivo Andonov: \n",
      "\tIvo Andonov, Ivo Andonov is a fictional character and one of...\n",
      "card 3793: The Bridge over the River Kwai: \n",
      "\tThe Bridge over the River Kwai, The Bridge over the River Kw...\n",
      "card 3794: $100 hamburger: \n",
      "\t$100 hamburger, $100 hamburger hundred-dollar hamburger is a...\n",
      "card 3795: Adrienne Johnson Kiriakis: \n",
      "\tAdrienne Johnson Kiriakis, Adrienne Johnson Kiriakis is a fi...\n",
      "card 3796: Paul Coker (EastEnders): \n",
      "\tPaul Coker EastEnders, Paul Coker is a character from the BB...\n",
      "card 3797: Char Aznable: \n",
      "\tChar Aznable, Char Aznable , Shaa Azunaburu, born Casval Rem...\n",
      "card 3798: Wilhelm von Humboldt: \n",
      "\tWilhelm von Humboldt, Friedrich Wilhelm Christian Karl Ferdi...\n",
      "card 3799: Errol Flynn: \n",
      "\tErrol Flynn, Errol Leslie Thomson Flynn 20 June 1909 14 Octo...\n",
      "card 3800: Gendarme (mountaineering): \n",
      "\tGendarme mountaineering, A gendarme is a pinnacle of rock on...\n",
      "card 3801: El Dorado (Super Friends): \n",
      "\tEl Dorado Super Friends, El Dorado is a Mexican superhero fe...\n",
      "card 3802: Paul Connor (Coronation Street): \n",
      "\tPaul Connor Coronation Street, Paul Connor is a fictional ch...\n",
      "card 3803: Anton Drexler: \n",
      "\tAnton Drexler, Anton Drexler 13 June 1884 24 February 1942 w...\n",
      "card 3804: Western religions: \n",
      "\tWestern religions, The Western religions are the religions t...\n",
      "card 3805: Chuck Norris facts: \n",
      "\tChuck Norris facts, Chuck Norris facts are satirical factoid...\n",
      "card 3806: Auxology: \n",
      "\tAuxology, Auxology,from Greek , aux, or , auxan, grow; and -...\n",
      "card 3807: Frakk, the Cats' Nightmare: \n",
      "\tFrakk, the Cats Nightmare, Frakk, a macskk rme lit. Frakk, t...\n",
      "card 3808: Bela Talbot: \n",
      "\tBela Talbot, Bela Talbot is a fictional character on The CW ...\n",
      "card 3809: 2014 celebrity nude photo leak: \n",
      "\t2014 celebrity nude photo leak, On August 31, 2014, a collec...\n",
      "card 3810: Jack Osborne: \n",
      "\tJack Osborne, Jack Osborne is a fictional character from the...\n",
      "card 3811: Private Godfrey: \n",
      "\tPrivate Godfrey, Private Charles Godfrey MM is a fictional H...\n",
      "card 3812: Ryan Sinclair: \n",
      "\tRyan Sinclair, Ryan Sinclair is a fictional character create...\n",
      "card 3813: Saul Tigh: \n",
      "\tSaul Tigh, Saul Tigh is a fictional character on Battlestar ...\n",
      "card 3814: Tylosis (botany): \n",
      "\tTylosis botany, In woody plants, a tylosis plural: tyloses i...\n",
      "card 3815: Help:Introduction: \n",
      "\tHelp:Introduction, ...\n",
      "card 3816: Description error: \n",
      "\tDescription error, A description error or selection error is...\n",
      "card 3817: Twelfth Doctor: \n",
      "\tTwelfth Doctor, The Twelfth Doctor is an incarnation of the ...\n",
      "card 3818: Swindler (Akudama Drive): \n",
      "\tSwindler Akudama Drive, Swindler Japanese: , Hepburn: Sagi-s...\n",
      "card 3819: Godwin's law: \n",
      "\tGodwins law, Godwins law, short for Godwins law or rule of N...\n",
      "card 3820: Internet: \n",
      "\tInternet, The Internet or internet is the global system of i...\n",
      "card 3821: Isadora Duncan: \n",
      "\tIsadora Duncan, Angela Isadora Duncan May 26, 1877 or May 27...\n",
      "card 3822: Jerry Lewis: \n",
      "\tJerry Lewis, Jerry Lewis born Joseph Levitch; March 16, 1926...\n",
      "card 3823: Obrazovanshchina: \n",
      "\tObrazovanshchina, Obrazovanshchina Russian: , educationdom, ...\n",
      "card 3824: Hayley Smith (Home and Away): \n",
      "\tHayley Smith Home and Away, Hayley Rose Smith also Lawson is...\n",
      "card 3825: Peter principle: \n",
      "\tPeter principle, The Peter principle is a concept in managem...\n",
      "card 3826: Colombo: \n",
      "\tColombo, Colombo k-LUM-boh; Sinhala: , romanized: Koamba, IP...\n",
      "card 3827: Alma Halliwell: \n",
      "\tAlma Halliwell, Alma Halliwell also Sedgewick and Baldwin is...\n",
      "card 3828: Cameo appearance: \n",
      "\tCameo appearance, A cameo role, also called a cameo appearan...\n",
      "using random article from wikipedia\n",
      "card 3829: Caroline Buxton: \n",
      "\tCaroline Buxton, Caroline Buxton is a fictional character on...\n"
     ]
    }
   ],
   "source": [
    "if runcode:\n",
    "    !python wiki_monikers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run From here to create Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python card_point_revision.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we create a deck of cards from the json file\n",
    "# !python card_engine.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "def determine_grade_level(summary: str):# -> float:\n",
    "    \"\"\"\n",
    "    determine_grade_level - generates a grade level for the given summary using the Flesch-Kincaid Grade Level formula\n",
    "\n",
    "    The Flesch-Kincaid Grade Level formula is a readability test designed to indicate how difficult a passage in English is to understand. The score is based on the average number of syllables per 100 words and the average number of words per sentence. The higher the score, the more difficult the text is to understand.\n",
    "\n",
    "    :param summary: _description_\n",
    "    :type summary: _type_\n",
    "    :return: _description_\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    grade_level = textstat.flesch_kincaid_grade(str(summary))\n",
    "    return grade_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the cards in the new_card_box folder\n",
    "if reset_cardbox:\n",
    "    !rm -rf new_card_box/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    !python balancing_the_deck.py\n",
    "except:\n",
    "    print('error in balancing the deck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ppn_deck.json', 'r') as read_file:\n",
    "    card_deck = json.load(read_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the cards, generate a grade_level score and add it to the json file under the key \"grade_level\"\n",
    "for card in tqdm(card_deck):\n",
    "    try:\n",
    "        summary = card['summary']\n",
    "        grade_level = determine_grade_level(summary)\n",
    "        card['grade_level'] = grade_level\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        # if there is an error, set the grade_level to 0\n",
    "        card['grade_level'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add length of summary to the df column \"summary_length\"\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(card_deck)\n",
    "df['summary_length'] = df['summary'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the card_deck to a json file, to a df using pandas and then to a csv file\n",
    "with open(\"ppn_deck_cleaned.json\", \"w\") as write_file:\n",
    "    json.dump(card_deck, write_file, indent=4)\n",
    "\n",
    "# read card_deck from ppn_deck.json file\n",
    "# with open(\"ppn_deck.json\", \"r\") as read_file:\n",
    "# card_deck = json.load(read_file)\n",
    "with open(\"ppn_deck_cleaned.json\", \"r\") as read_file:\n",
    "    card_deck = json.load(read_file)\n",
    "    \n",
    "# convert card_deck to a pandas dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points for the card should be calculated by the following formula:\n",
    "# - the higher the grade level of the card, the higher the points.\n",
    "# - the more words in the summary, the lower the points.\n",
    "# - cards with longer titles should have higher points.\n",
    "# - cards with Acronyms should have higher points.\n",
    "\n",
    "# create a new column in the dataframe called \"points_for_card\"\n",
    "df['points_for_card'] = 0\n",
    "df['acronym'] = False # this will need to be updated later to determine if the card has an acronym or not\n",
    "\n",
    "def determine_points(card):\n",
    "    # determine the points for the card based on the following formula:\n",
    "    # - the higher the grade level of the card, the higher the points.\n",
    "    # - the more words in the summary, the lower the points.\n",
    "    # - cards with longer titles should have higher points.\n",
    "    # - cards with Acronyms should have higher points.\n",
    "    grade_level = card['grade_level']\n",
    "    summary = card['summary']\n",
    "    title = card['title']\n",
    "    acronym = card['acronym']\n",
    "    related_pages = card['related']\n",
    "    points = 0\n",
    "    # - the higher the grade level of the card, the higher the points.\n",
    "    # all _score variables will be between 0 and 100\n",
    "    grade_score = grade_level\n",
    "    # - the more words in the summary, the lower the points.\n",
    "    if isinstance(summary, str):\n",
    "        summary_score = len(summary.split())\n",
    "    else:\n",
    "        summary_score = len(summary)\n",
    "    # - cards with longer titles should have higher points.\n",
    "    if isinstance(title, str):\n",
    "        title_score = len(title.split())\n",
    "    else:\n",
    "        title_score = len(title)\n",
    "    # - cards with Acronyms should have higher points.\n",
    "    acronym_score = 0\n",
    "    if acronym:\n",
    "        acronym_score = 1\n",
    "    # - cards with related pages should have higher points.\n",
    "    try:\n",
    "        related_pages_score = int(related_pages)\n",
    "    except ValueError:\n",
    "        related_pages_score = 0\n",
    "    except Exception:\n",
    "        related_pages_score = 0\n",
    "    #print(grade_score)\n",
    "    #print(summary_score)\n",
    "    #print(title_score)\n",
    "    #print(acronym_score)\n",
    "\n",
    "    #print(related_pages_score)\n",
    "\n",
    "    # calculate the points\n",
    "    points = grade_score + summary_score + title_score + acronym_score + related_pages_score\n",
    "    #print(points)\n",
    "\n",
    "    return int(points)\n",
    "\n",
    "# apply the determine_points function to each of the cards in the dataframe\n",
    "df['points_for_card'] = df.apply(determine_points, axis=1)\n",
    "# now scale the points_for_card column to be between 1 and 10, and round to the nearest integer\n",
    "df['points_for_card'] = df['points_for_card'].apply(lambda x: round((x - df['points_for_card'].min()) / (df['points_for_card'].max() - df['points_for_card'].min()) * 10))\n",
    "# replace any points_for_card values that are 0 with 1\n",
    "df['points_for_card'] = df['points_for_card'].apply(lambda x: 1 if x == 0 else x)\n",
    "# no card with a grade level above 10 should have a points_for_card value less than 5\n",
    "df['points_for_card'] = df.apply(lambda x: 5 if x['grade_level'] > 10 and x['points_for_card'] < 5 else x['points_for_card'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['years_in_summary'] = df['summary'].apply(lambda x: len(re.findall(r'\\d{4}', str(x))))\n",
    "df['years_in_title'] = df['title'].apply(lambda x: len(re.findall(r'\\d{4}', str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for years in the summary and title. Older cards should have higher points, so we will add 1 point for each year found in the summary and title (this will be scaled later)\n",
    "import re\n",
    "\n",
    "def points_by_year_mentioned(this_card,years_in_deck):\n",
    "    # assign higher points for years that are older (i.e 1980 has higher points than 2010 etc.) This is on a scale so highest points are for the oldest years.\n",
    "    # this card may mention multiple years, so we will add the points for each year mentioned by where it falls in the scale of years in the deck.\n",
    "    # for example, if the card mentions 1980 and 2010, and the deck has cards from 1980 to 2020, then the points for the card will be 1 + 10 = 11\n",
    "    points = 0\n",
    "    years_in_summary = this_card['years_in_summary']\n",
    "    years_in_title = this_card['years_in_title']\n",
    "    years_mentioned = years_in_summary + years_in_title\n",
    "    if years_mentioned > 0:\n",
    "        # get the year mentioned in the summary and title\n",
    "        years = re.findall(r'\\d{4}', this_card['summary']) + re.findall(r'\\d{4}', this_card['title'])\n",
    "        # convert the years to integers\n",
    "        years = [int(x) for x in years]\n",
    "        # get the min and max year in the deck\n",
    "        min_year = min(years_in_deck)\n",
    "        max_year = max(years_in_deck)\n",
    "        # get the range of years in the deck\n",
    "        range_of_years = max_year - min_year\n",
    "        # get the range of points\n",
    "        range_of_points = 10\n",
    "        # get the points for each year mentioned\n",
    "        for year in years:\n",
    "            try:\n",
    "                points_for_year = round((year - min_year) / range_of_years * range_of_points)\n",
    "                points += points_for_year\n",
    "            except ZeroDivisionError:\n",
    "                points += 0 # if the range of years is 0, then the points for the year will be 0\n",
    "            except Exception:\n",
    "                points += 0\n",
    "    return points\n",
    "\n",
    "# get the years in the deck by looking at all summaries and titles for years and getting the unique years mentioned. years are between 1950 and 2022.\n",
    "years_in_deck = []\n",
    "# convert the row summary, title to a string type\n",
    "df['summary'] = df['summary'].apply(lambda x: str(x))\n",
    "df['title'] = df['title'].apply(lambda x: str(x))\n",
    "for index, row in df.iterrows():\n",
    "    years_in_deck += re.findall(r'\\d{4}', row['summary'])\n",
    "    years_in_deck += re.findall(r'\\d{4}', row['title'])\n",
    "# convert the years to integers\n",
    "years_in_deck = [int(x) for x in years_in_deck]\n",
    "# get the unique years\n",
    "years_in_deck = list(set([int(x) for x in years_in_deck]))\n",
    "# sort the years\n",
    "years_in_deck.sort()\n",
    "# filter out years that are not between 1950 and 2022\n",
    "years_in_deck = [x for x in years_in_deck if x >= 1950 and x <= 2022]\n",
    "# print(years_in_deck)\n",
    "# apply the points_by_year_mentioned function to each of the cards in the dataframe\n",
    "df['points_by_year_mentioned'] = df.apply(lambda x: points_by_year_mentioned(x,years_in_deck), axis=1)\n",
    "\n",
    "# now scale the points_by_year_mentioned column to be between 1 and 10, and round to the nearest integer\n",
    "try:\n",
    "    df['points_by_year_mentioned'] = df['points_by_year_mentioned'].apply(lambda x: round((x - df['points_by_year_mentioned'].min()) / (df['points_by_year_mentioned'].max() - df['points_by_year_mentioned'].min()) * 10))\n",
    "except ZeroDivisionError:\n",
    "    df['points_by_year_mentioned'] = 0 # if the range of years is 0, then the points for the year will be 0\n",
    "except ValueError:\n",
    "    df['points_by_year_mentioned'] = 0 # if the range of years is 0, then the points for the year will be 0\n",
    "\n",
    "# replace any points_by_year_mentioned values that are 0 with 1\n",
    "df['points_by_year_mentioned'] = df['points_by_year_mentioned'].apply(lambda x: 1 if x == 0 else x)\n",
    "\n",
    "# now add the points_by_year_mentioned to the points_for_card\n",
    "df['points_for_card'] = df['points_for_card'] + df['points_by_year_mentioned']\n",
    "\n",
    "try:\n",
    "    # now scale the points_for_card column to be between 1 and 10, and round to the nearest integer\n",
    "    df['points_for_card'] = df['points_for_card'].apply(lambda x: round((x - df['points_for_card'].min()) / (df['points_for_card'].max() - df['points_for_card'].min()) * 10))\n",
    "except ZeroDivisionError:\n",
    "    df['points_for_card'] = 0 # if the range of years is 0, then the points for the year will be 0\n",
    "except ValueError:\n",
    "    df['points_for_card'] = 0 # if the range of years is 0, then the points for the year will be 0\n",
    "except Exception:\n",
    "    df['points_for_card'] = 0 # if the range of years is 0, then the points for the year will be 0\n",
    "    raise(Exception, 'Error in scaling points_for_card')\n",
    "    # replace any points_for_card values that are 0 with 1\n",
    "    df['points_for_card'] = df['points_for_card'].apply(lambda x: 1 if x == 0 else x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cards that are beyond the 95th percentile using IQR method\n",
    "# calculate the 95th percentile\n",
    "grade_level_95th_percentile = df['grade_level'].quantile(0.95)\n",
    "# remove cards that are beyond the 95th percentile\n",
    "df = df[df['grade_level'] < grade_level_95th_percentile]\n",
    "# remove any cards with negative point values or grade levels\n",
    "df = df[df['point_value'] > 0]\n",
    "df = df[df['grade_level'] > 0]\n",
    "# show the distribution of grade levels\n",
    "\n",
    "# plot grade levels vs point values\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(df['grade_level'], df['points_for_card'], color='red', alpha=0.5, s=1)\n",
    "plt.xlabel('Grade Level')\n",
    "plt.ylabel('Point Value (points_for_card)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use min-max normalization to normalize the point values\n",
    "# calculate the min and max point values\n",
    "min_point_value = df['points_for_card'].min()\n",
    "max_point_value = df['points_for_card'].max()\n",
    "# normalize the point values\n",
    "df['points_for_card'] = (df['points_for_card'] - min_point_value) / (max_point_value - min_point_value)\n",
    "# plot grade levels vs point values\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(df['grade_level'], df['points_for_card'], color='red', alpha=0.5, s=1)\n",
    "plt.xlabel('Grade Level')\n",
    "plt.ylabel('Point Value (points_for_card)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use minmaxscaler to normalize the point values between 0, and 10 by steps of 1 (i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10) using rounding to the nearest integer. This will be used to generate the point values for the cards.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "# create a MinMaxScaler object\n",
    "scaler = MinMaxScaler(feature_range=(1, 10))\n",
    "# fit the scaler to the point values\n",
    "if df[['points_for_card']].empty:\n",
    "    # handle empty dataframe\n",
    "    raise ValueError('Empty dataframe')\n",
    "else:\n",
    "    scaler.fit(df[['points_for_card']])\n",
    "# transform the point values\n",
    "df['points_for_card'] = scaler.transform(df[['points_for_card']])\n",
    "# round the point values to the nearest integer\n",
    "df['points_for_card'] = df['points_for_card'].round()\n",
    "# plot grade levels vs point values\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(df['grade_level'], df['points_for_card'], color='red', alpha=0.5, s=1)\n",
    "plt.xlabel('Grade Level')\n",
    "plt.ylabel('Point Value (points_for_card)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a json file in place of the ppn_deck.json file\n",
    "df.to_json('ppn_deck.json', orient='records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now remove any cards with profanity in the title or summary\n",
    "# !pip install sklearn --upgrade\n",
    "# !pip install joblib --upgrade\n",
    "# !pip install scipy --upgrade\n",
    "# !pip install alt-profanity-check\n",
    "from profanity_check import predict, predict_prob\n",
    "# if the probability of profanity is greater than 0.7, then remove the card.\n",
    "print(f'Number of cards before removing profanity: {len(df)}')\n",
    "cards = len(df)\n",
    "df['profanity'] = (predict_prob(df['title']) + predict_prob(df['summary'])) / 2 # calculate the average probability of profanity in the title and summary. This is a value between 0 and 1.\n",
    "df = df[df['profanity'] < 0.7] # remove any cards with a probability of profanity greater than 0.7\n",
    "df = df.drop(columns=['profanity']) # remove the profanity column\n",
    "# save the dataframe to a json file in place of the ppn_deck.json file\n",
    "print(f'Number of cards after removing profanity: {len(df)}')\n",
    "final_cards= len(df)\n",
    "# if there were cards with profanity then clear the deck folder and re-generate the deck files\n",
    "reset_cardbox = True if cards != final_cards else False # if the number of cards before removing profanity is not equal to the number of cards after removing profanity, then reset the cardbox because there were cards with profanity ratings over 70%.\n",
    "df.to_json('ppn_deck_clean.json', orient='records')\n",
    "if reset_cardbox:\n",
    "    !rm -rf new_card_box/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if reset_cardbox:\n",
    "    # save a backup of the original deck\n",
    "    timestamp = time.strftime('%Y%m%d_%H%M%S') # get the current timestamp in the format YYYYMMDD_HHMMSS\n",
    "    !cp ppn_deck.json ppn_deck_backup_{timestamp}.json # save a backup of the original deck in case something goes wrong\n",
    "    !rm -rf new_card_box/*\n",
    "    substitute_master_deck = True # if there were cards with profanity then clear the deck folder and re-generate the deck files\n",
    "else:\n",
    "    substitute_master_deck = False\n",
    "    \n",
    "if substitute_master_deck:\n",
    "    # save the df to a json file in place of the ppn_deck.json file\n",
    "    df.to_json('ppn_deck.json', orient='records')\n",
    "    print(f'Saved cleaned deck to ppn_deck.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "\n",
    "# import contextualSpellCheck\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# contextualSpellCheck.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a deck of cards from the json file\n",
    "!python card_engine.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('groupme')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28dd76f97a2595215b3511d9563b8125e93469ee739d17a6b25584482d270cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
