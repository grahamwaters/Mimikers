{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.corpus import stopwords\n",
    "# PlaintextParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "# LexRankSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "# LsaSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "# define Tokenizer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "# define Stemmer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "# define language\n",
    "pytrend = TrendReq(hl='en-US', tz=360)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "# with open(\"ppn_deck_cleaned.json\", \"w\") as write_file:\n",
    "#     json.dump(card_deck, write_file, indent=4)\n",
    "\n",
    "# read card_deck from ppn_deck.json file\n",
    "with open(\"ppn_deck.json\", \"r\") as read_file:\n",
    "    card_deck = json.load(read_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this script parses downloaded cards for blacklisted words and removes the cards from the deck.\n",
    "\n",
    "blacklist = ['fuck','shit']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3980/3996 [00:00<00:00, 255883.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing card: Shadow Hearts: Covenant\n",
      "Removing card: How to Be a Complete Bastard\n",
      "Removing card: How to Be a Complete Bastard\n",
      "list.remove(x): x not in list\n",
      "Removing card: Gearless Joe\n",
      "Removing card: Mega Man 9\n",
      "Removing card: The Show Must Go On (Queen song)\n",
      "Removing card: Suikoden\n",
      "Removing card: Work Time Fun\n",
      "Removing card: Osomatsu-kun\n",
      "Removing card: Go the Fuck to Sleep\n",
      "Removing card: Go the Fuck to Sleep\n",
      "list.remove(x): x not in list\n",
      "Removing card: Shadow Hearts (video game)\n",
      "Removing card: Tales of Vesperia\n",
      "Removing card: Otome wa Boku ni Koishiteru\n",
      "Removing card: Otome wa Boku ni Koishiteru\n",
      "list.remove(x): x not in list\n",
      "Removing card: Lords of Thunder\n",
      "Removing card: Techno Viking\n",
      "Removing card: International State College of the Philippines\n",
      "Removing card: Dat Boi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for each card in the deck\n",
    "# check that card's title and description for blacklisted words, and remove the card if it contains any\n",
    "for card in tqdm(card_deck):\n",
    "    # check title for blacklisted words\n",
    "    for word in blacklist:\n",
    "        if word in card['title'].lower():\n",
    "            print(f'Removing card: {card[\"title\"]}')\n",
    "            card_deck.remove(card)\n",
    "            break\n",
    "    # check description for blacklisted words\n",
    "    for word in blacklist:\n",
    "        if word in card['summary'][1].lower():\n",
    "            print(f'Removing card: {card[\"title\"]}')\n",
    "            try:\n",
    "                card_deck.remove(card)\n",
    "            except Exception as e:\n",
    "                print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
