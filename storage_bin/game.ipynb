{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rapist*)|(christ)|(ass)|(sex*)|(hoe)|(cock*)|(damn*)|(slut*)|(titt*)|(christians)|(pedo*)| (fellatio)|(jesus)|(asse*)|(genit*)|(christianity)|(atheists)| (masterb*)|(gay)|(bible)|(muslim)| (bitch*)|(jew*)|(nipple*)|(religion)| (dick*)| (ho )|(praye)|(islam)|(-ass*)|(jugs)|(atheism)|(tit*)|(rape*)|(atheist)| (bastard*)|(penis)|(yeshua)| (puss*)|(whor*)|(fagg*)|(allah)|(erotic*)|(balls)|(god)|(penal)|(fuck*)|(christian)| (fuck)| (nigg*)|(boob*)|(peni*)|(boob)|(ejaculate)|(lord)|(shit)|(nigg*)|(faith)| (cunt*)|(islamic)| (breast*)|(yahwey)|(nipples)|(blowjob)| (nud*)|(breast*)| (porn*)| (naked)|(pray)| (nipple*)|(mastu)|(lynch)|(church)|(israel*)\n"
     ]
    }
   ],
   "source": [
    "import urbandictionary as ud\n",
    "import re\n",
    "import json\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "import wikipedia\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import PyDictionary\n",
    "from PyDictionary import PyDictionary\n",
    "#import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "bad_patterns = r\"(rapist*)|(christ)|(ass)|(sex*)|(hoe)|(cock*)|(mastu)|(damn*)|(slut*)|(church)|(christians)|(pedo*)|(titt*)|(jesus)|(asse*)|(israel*)| (fellatio)|(genit*)|(christianity)|(atheists)| (masterb*)|(gay)|(bible)|(muslim)| (bitch*)|(jew*)|(nipple*)|(religion)| (dick*)| (ho )|(praye)|(islam)|(jugs)|(atheism)|(tit*)|(rape*)|(atheist)| (bastard*)|(penis)|(yeshua)| (puss*)|(whor*)|(fagg*)|(allah)|(erotic*)|(balls)|(penal)|(fuck*)|(christian)| (fuck)| (nigg*)|(boob*)|(peni*)|(boob)|(ejaculate)|(lord)|(shit)|(faith)| (cunt*)|(islamic)| (breast*)|(yahwey)|(nipples)|(blowjob)| (nud*)|(breast*)| (porn*)| (naked)|(pray)| (nipple*)|(-ass*)|(lynch)|(nigg*)|(god)\"\n",
    "\n",
    "# Split the string into a list of words\n",
    "bad_patterns_list = re.split(r'\\|', bad_patterns)\n",
    "\n",
    "# Remove duplicates from the list\n",
    "bad_patterns_list = list(set(bad_patterns_list))\n",
    "\n",
    "# Join the list back into a string\n",
    "bad_patterns = '|'.join(bad_patterns_list)\n",
    "\n",
    "print(bad_patterns)\n",
    "\n",
    "replacements = {\n",
    "    '\\bsex*': 'affection',\n",
    "    '\\bporn*': 'adult entertainment',\n",
    "    '\\bfuck*': 'intercourse',\n",
    "    '-ass*': 'rear end',\n",
    "    'ass': 'rear end',\n",
    "    '\\bshit': 'feces',\n",
    "    'damn*': 'darn',\n",
    "    'ass|asse*': 'rear end',\n",
    "    'cock*': 'male bird',\n",
    "    'whor*': 'prostitute',\n",
    "    'nigg*': 'racial slur',\n",
    "    'slut*': 'promiscuous person',\n",
    "    'blowjob': 'oral sex',\n",
    "    'fagg*': 'homosexual',\n",
    "    'boob|boob*': 'breast',\n",
    "    'bitch*': 'mean woman',\n",
    "    'bastard*': 'illegitimate child',\n",
    "    'ho |hoe': 'prostitute',\n",
    "    'breast*|jugs': 'chest',\n",
    "    'cunt*': 'vulva',\n",
    "    'puss*': 'vagina',\n",
    "    'dick*': 'penis',\n",
    "    'naked': 'unclothed',\n",
    "    'nud*': 'unclothed',\n",
    "    'masterb*': 'self-gratification',\n",
    "    'mastu': 'self-gratification',\n",
    "    'god':'deity',\n",
    "    'jesus':'religious figure',\n",
    "    'christ':'religious figure',\n",
    "    'bible':'religious text',\n",
    "    'church':'place of worship',\n",
    "    'religion':'set of beliefs',\n",
    "    'pray':'to communicate with a deity',\n",
    "    'prayer':'a conversation with a deity',\n",
    "    'faith':'belief',\n",
    "    'lord':'captain',\n",
    "    'allah':'a diety',\n",
    "    'gay':'homosexual',\n",
    "    'rapist*|rape*': 'sexual assault',\n",
    "    'pedo*': 'child sexual abuse(r)',\n",
    "    'yahwey':'a deity',\n",
    "    'yeshua':'a religious figure'\n",
    "}\n",
    "\n",
    "def replacer_censor(definition,phrase,replacements_dict):\n",
    "    # Iterate over the keys in the replacements dictionary\n",
    "    for pattern in replacements_dict:\n",
    "        # Use re.sub to replace the occurrences of the pattern with its corresponding value in the phrase and definition strings\n",
    "        phrase = re.sub(pattern, replacements_dict[pattern], phrase)\n",
    "        definition = re.sub(pattern, replacements_dict[pattern], definition)\n",
    "    return phrase, definition\n",
    "\n",
    "def check_for_badwords(definition, phrase, bad_patterns, replacements_dict):\n",
    "    # Replace the bad words with their corresponding replacements\n",
    "    phrase, definition = replacer_censor(definition, phrase, replacements_dict)\n",
    "\n",
    "    # Check if the phrase or definition contain any of the bad patterns\n",
    "    if any(re.search(r'\\b' + word + r'\\b', definition) for word in bad_patterns) or any(re.search(r'\\b' + word + r'\\b', phrase) for word in bad_patterns):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_for_good_patterns(definition, title):\n",
    "    # check both title and definition for good patterns\n",
    "    good_patterns = [r'\\b\\w+phobia\\.?\\b', r'\\bslang\\b', r'\\bacronymn\\b', r'\\bmeme\\b']\n",
    "\n",
    "\n",
    "    if any(re.match(r'\\b' + word + r'\\b', definition) for word in good_patterns):\n",
    "        print(f'Found a good pattern in the definition: {definition}')\n",
    "        return True\n",
    "    elif any(re.match(r'\\b' + word + r'\\b', title) for word in good_patterns):\n",
    "        print(f'Found a good pattern in the title: {title}')\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def remove_undesireable_sentences(definition, title, bad_patterns):\n",
    "    # convert the definition and title to lowercase\n",
    "    definition = definition.lower()\n",
    "    title = title.lower()\n",
    "\n",
    "    # split the definition into sentences\n",
    "    sentences = definition.split('.')\n",
    "\n",
    "    # split the title into words\n",
    "    title_words = title.split()\n",
    "\n",
    "    # initialize a list to store the acceptable sentences\n",
    "    acceptable_sentences = []\n",
    "\n",
    "    # iterate over the sentences in the definition\n",
    "    for sentence in sentences:\n",
    "        # split the sentence into words\n",
    "        sentence_words = sentence.split()\n",
    "\n",
    "        # check if any of the words in the sentence are also in the title\n",
    "        if not any(word in title_words for word in sentence_words):\n",
    "            # if not, add the sentence to the list of acceptable sentences\n",
    "            acceptable_sentences.append(sentence)\n",
    "\n",
    "    # remove sentences that are not in English\n",
    "    definition = re.sub(r'[^\\x00-\\x7f]',r'', '.'.join(acceptable_sentences))\n",
    "    # remove sentences that contain a regex match to any word in the buzzwords list\n",
    "    definition = re.sub(r'|'.join(map(re.escape, bad_patterns)), '', definition)\n",
    "    return definition\n",
    "\n",
    "def unpack_definitions(definition):\n",
    "    # remove the brackets and clean up the definitions\n",
    "    # with regex\n",
    "    definition = definition.replace(\"[\",\"\")\n",
    "    definition = definition.replace(\"]\",\"\")\n",
    "    definition = definition.replace(\"'\",\"\")\n",
    "    definition = definition.replace('\"',\"\")\n",
    "    definition = definition.replace(\"(\",\"\")\n",
    "    definition = definition.replace(\")\",\"\")\n",
    "\n",
    "    # remove double spaces\n",
    "    definition = definition.replace('  ',' ')\n",
    "\n",
    "    return definition\n",
    "\n",
    "def get_page_length(phrase):\n",
    "  # search for pages on Wikipedia that match the given phrase\n",
    "    try:\n",
    "        pages = wikipedia.search(phrase)\n",
    "\n",
    "        # retrieve the first page from the search results\n",
    "        page = wikipedia.page(pages[0])\n",
    "        print(f'Found the page for {page.title}', end='')\n",
    "        if phrase.lower() != page.title.lower():\n",
    "            print(' ... nevermind... not the right page.')\n",
    "            return 0\n",
    "        # return the length of the page\n",
    "        return len(page.content)\n",
    "    except Exception as e:\n",
    "            return 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Set up variables\n",
    "    wikitest = False # set to true to test the wikipedia page length\n",
    "    rand_dict = {}\n",
    "    total_votes_thresh = 100 # min number of upvotes + downvotes\n",
    "    upvotes_thresh = 100 # min number of upvotes for a single word to count  as a card\n",
    "    downvotes_thresh = upvotes_thresh//2 # max number of downvotes\n",
    "    desired_number_of_cards = 30 # number of cards to generate\n",
    "    rands = [] # the randoms\n",
    "\n",
    "    # Get random phrases and definitions from Urban Dictionary until desired number of cards is reached\n",
    "    while len(rand_dict) < desired_number_of_cards:\n",
    "        time.sleep(1)\n",
    "        rand = ud.random() # returns a list of 5 random phrases and definitions from Urban Dictionary\n",
    "        rands.extend(rand) # rands is a list of all the random phrases and definitions from Urban Dictionary\n",
    "        for element in rand:\n",
    "            phrase = element.word\n",
    "            definition = element.definition\n",
    "            upvotes = element.upvotes\n",
    "            downvotes = element.downvotes\n",
    "            values = [upvotes + downvotes >= total_votes_thresh,\n",
    "                      upvotes >= upvotes_thresh and downvotes <= downvotes_thresh,\n",
    "                      check_for_good_patterns(definition, phrase),\n",
    "                      len(phrase.split()) > 1] # check if the phrase is more than one word (final check)\n",
    "\n",
    "            # Check if the element meets the criteria to be added to the dictionary\n",
    "            if any(values) and not check_for_badwords(definition, phrase, bad_patterns, replacements):\n",
    "                # Clean up and format the definition\n",
    "                definition = unpack_definitions(definition)\n",
    "                definition = remove_undesireable_sentences(definition, phrase, bad_patterns)\n",
    "                # Add the element to the dictionary\n",
    "                print(f'{upvotes} | Added {phrase}: {definition[0:10]}...')\n",
    "                rand_dict[phrase] = definition\n",
    "    # Save the dictionary to a CSV and JSON file\n",
    "    df = pd.DataFrame.from_dict(rand_dict, orient='index')\n",
    "    df.to_csv('cards.csv', header=False)\n",
    "    with open('cards.json', 'w') as f:\n",
    "        json.dump(rand_dict, f)\n",
    "\n",
    "\n",
    "    # Hippopotomonstrosesquippedaliophobia - fear of long words\n",
    "    # \"nachlophobia\": \"the fear that your ultimate connection has people are actually pretty shallow and even though you consider them close you refuse to let them see the real you use of fear of you losing them as a repercussion of your fears, hopes and dreams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "missing ), unterminated subpattern at position 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_68856/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_68856/3950411203.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# Check if the element meets the criteria to be added to the dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_for_badwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad_patterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Clean up and format the definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mdefinition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_definitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_68856/3950411203.py\u001b[0m in \u001b[0;36mcheck_for_badwords\u001b[0;34m(definition, phrase, bad_patterns, replacements_dict)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# Check if the phrase or definition contain any of the bad patterns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\b'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr'\\b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefinition\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbad_patterns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\b'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr'\\b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbad_patterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/34/d1tlq3k91hb0lj6x90xpzb4r0000gn/T/ipykernel_68856/3950411203.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# Check if the phrase or definition contain any of the bad patterns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\b'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr'\\b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefinition\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbad_patterns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\b'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr'\\b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbad_patterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    200\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    445\u001b[0m                            not nested and not items))\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_verbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnested\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                 raise source.error(\"missing ), unterminated subpattern\",\n\u001b[0m\u001b[1;32m    844\u001b[0m                                    source.tell() - start)\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: missing ), unterminated subpattern at position 2"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
